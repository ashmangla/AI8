{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJXW_DgiSebM"
      },
      "source": [
        "# LangGraph and LangSmith - Agentic RAG Powered by LangChain\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "- ü§ù Breakout Room #1:\n",
        "  1. Install required libraries\n",
        "  2. Set Environment Variables\n",
        "  3. Creating our Tool Belt\n",
        "  4. Creating Our State\n",
        "  5. Creating and Compiling A Graph!\n",
        "\n",
        "- ü§ù Breakout Room #2:\n",
        "  1. Evaluating the LangGraph Application with LangSmith\n",
        "  2. Adding Helpfulness Check and \"Loop\" Limits\n",
        "  3. LangGraph for the \"Patterns\" of GenAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djQ3nRAgoF67"
      },
      "source": [
        "# ü§ù Breakout Room #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7pQDUhUnIo8"
      },
      "source": [
        "## Part 1: LangGraph - Building Cyclic Applications with LangChain\n",
        "\n",
        "LangGraph is a tool that leverages LangChain Expression Language to build coordinated multi-actor and stateful applications that includes cyclic behaviour.\n",
        "\n",
        "### Why Cycles?\n",
        "\n",
        "In essence, we can think of a cycle in our graph as a more robust and customizable loop. It allows us to keep our application agent-forward while still giving the powerful functionality of traditional loops.\n",
        "\n",
        "Due to the inclusion of cycles over loops, we can also compose rather complex flows through our graph in a much more readable and natural fashion. Effectively allowing us to recreate application flowcharts in code in an almost 1-to-1 fashion.\n",
        "\n",
        "### Why LangGraph?\n",
        "\n",
        "Beyond the agent-forward approach - we can easily compose and combine traditional \"DAG\" (directed acyclic graph) chains with powerful cyclic behaviour due to the tight integration with LCEL. This means it's a natural extension to LangChain's core offerings!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_fLDElOVoop"
      },
      "source": [
        "## Task 1:  Dependencies\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wujPjGJuoPwg"
      },
      "source": [
        "## Task 2: Environment Variables\n",
        "\n",
        "We'll want to set our OpenAI, Tavily, and LangSmith API keys along with our LangSmith environment variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdh8CoVWHRvs",
        "outputId": "3fa78560-393c-4ee5-b871-9886bf0d70f4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jkla2fpx28QK",
        "outputId": "52d7ad22-fcb1-4abe-853b-216c55a12650"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv0glIDyHmRt",
        "outputId": "b69df90a-b4e1-4ddb-9de0-882d98b68ab2"
      },
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE8 - LangGraph - {uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBRyQmEAVzua"
      },
      "source": [
        "## Task 3: Creating our Tool Belt\n",
        "\n",
        "As is usually the case, we'll want to equip our agent with a toolbelt to help answer questions and add external knowledge.\n",
        "\n",
        "There's a tonne of tools in the [LangChain Community Repo](https://github.com/langchain-ai/langchain-community/tree/main/libs/community) but we'll stick to a couple just so we can observe the cyclic nature of LangGraph in action!\n",
        "\n",
        "We'll leverage:\n",
        "\n",
        "- [Tavily Search Results](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/tavily_search/tool.py)\n",
        "- [Arxiv](https://github.com/langchain-ai/langchain-community/blob/main/libs/community/langchain_community/tools/arxiv/tool.py)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k6n_Dob2F46"
      },
      "source": [
        "#### üèóÔ∏è Activity #1:\n",
        "\n",
        "Please add the tools to use into our toolbelt.\n",
        "\n",
        "> NOTE: Each tool in our toolbelt should be a method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/ashimamangla/AI_Makerspace/code/AI8/05_Our_First_Agent_with_LangGraph/.venv/bin/python: No module named pip\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "/Users/ashimamangla/AI_Makerspace/code/AI8/05_Our_First_Agent_with_LangGraph/.venv/bin/python: No module named pip\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU duckduckgo-search langchain-community\n",
        "%pip install -U ddgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lAxaSvlfIeOg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/2k/24tggmp93z152ndxyqxtq4q80000gn/T/ipykernel_79312/1389074315.py:6: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
            "  tavily_tool = TavilySearchResults(max_results=5)\n"
          ]
        }
      ],
      "source": [
        "#from langchain_tavily import TavilySearchResults\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain_community.tools.arxiv.tool import ArxivQueryRun\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "tavily_tool = TavilySearchResults(max_results=5)\n",
        "\n",
        "tool_belt = [\n",
        "    tavily_tool,\n",
        "    ArxivQueryRun(),\n",
        "    DuckDuckGoSearchRun(),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI-C669ZYVI5"
      },
      "source": [
        "### Model\n",
        "\n",
        "Now we can set-up our model! We'll leverage the familiar OpenAI model suite for this example - but it's not *necessary* to use with LangGraph. LangGraph supports all models - though you might not find success with smaller models - as such, they recommend you stick with:\n",
        "\n",
        "- OpenAI's GPT-3.5 and GPT-4\n",
        "- Anthropic's Claude\n",
        "- Google's Gemini\n",
        "\n",
        "> NOTE: Because we're leveraging the OpenAI function calling API - we'll need to use OpenAI *for this specific example* (or any other service that exposes an OpenAI-style function calling API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QkNS8rNZJs4z"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4.1-nano\", temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugkj3GzuZpQv"
      },
      "source": [
        "Now that we have our model set-up, let's \"put on the tool belt\", which is to say: We'll bind our LangChain formatted tools to the model in an OpenAI function calling format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4OdMqFafZ_0V"
      },
      "outputs": [],
      "source": [
        "model = model.bind_tools(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERzuGo6W18Lr"
      },
      "source": [
        "#### ‚ùì Question #1:\n",
        "\n",
        "How does the model determine which tool to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ‚úÖ Answer:\n",
        "Model uses \n",
        "(I) Structured approach : function calling based on prompt and the tool description given. A natural language query or prompt will get converted to a function call. A tool/function definition incudes name, description of what it does and input paramaters in json format. The Model analyzes the input prompt and matches it with tools in tool belt - it will check for (1)relevance: is a tool relevant to the input query  (2) Does the tool functionality match the user request (3) does it have the input parameters the tool needs\n",
        "(II) (more freeform) ReAct Prompting : Agent uses the model to reason about the tool it should use and what inputs to provide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_296Ub96Z_H8"
      },
      "source": [
        "## Task 4: Putting the State in Stateful\n",
        "\n",
        "Earlier we used this phrasing:\n",
        "\n",
        "`coordinated multi-actor and stateful applications`\n",
        "\n",
        "So what does that \"stateful\" mean?\n",
        "\n",
        "To put it simply - we want to have some kind of object which we can pass around our application that holds information about what the current situation (state) is. Since our system will be constructed of many parts moving in a coordinated fashion - we want to be able to ensure we have some commonly understood idea of that state.\n",
        "\n",
        "LangGraph leverages a `StatefulGraph` which uses an `AgentState` object to pass information between the various nodes of the graph.\n",
        "\n",
        "There are more options than what we'll see below - but this `AgentState` object is one that is stored in a `TypedDict` with the key `messages` and the value is a `Sequence` of `BaseMessages` that will be appended to whenever the state changes.\n",
        "\n",
        "Let's think about a simple example to help understand exactly what this means (we'll simplify a great deal to try and clearly communicate what state is doing):\n",
        "\n",
        "1. We initialize our state object:\n",
        "  - `{\"messages\" : []}`\n",
        "2. Our user submits a query to our application.\n",
        "  - New State: `HumanMessage(#1)`\n",
        "  - `{\"messages\" : [HumanMessage(#1)}`\n",
        "3. We pass our state object to an Agent node which is able to read the current state. It will use the last `HumanMessage` as input. It gets some kind of output which it will add to the state.\n",
        "  - New State: `AgentMessage(#1, additional_kwargs {\"function_call\" : \"WebSearchTool\"})`\n",
        "  - `{\"messages\" : [HumanMessage(#1), AgentMessage(#1, ...)]}`\n",
        "4. We pass our state object to a \"conditional node\" (more on this later) which reads the last state to determine if we need to use a tool - which it can determine properly because of our provided object!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mxL9b_NZKUdL"
      },
      "outputs": [],
      "source": [
        "from typing import TypedDict, Annotated\n",
        "from langgraph.graph.message import add_messages\n",
        "import operator\n",
        "from langchain_core.messages import BaseMessage\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWsMhfO9grLu"
      },
      "source": [
        "## Task 5: It's Graphing Time!\n",
        "\n",
        "Now that we have state, and we have tools, and we have an LLM - we can finally start making our graph!\n",
        "\n",
        "Let's take a second to refresh ourselves about what a graph is in this context.\n",
        "\n",
        "Graphs, also called networks in some circles, are a collection of connected objects.\n",
        "\n",
        "The objects in question are typically called nodes, or vertices, and the connections are called edges.\n",
        "\n",
        "Let's look at a simple graph.\n",
        "\n",
        "![image](https://i.imgur.com/2NFLnIc.png)\n",
        "\n",
        "Here, we're using the coloured circles to represent the nodes and the yellow lines to represent the edges. In this case, we're looking at a fully connected graph - where each node is connected by an edge to each other node.\n",
        "\n",
        "If we were to think about nodes in the context of LangGraph - we would think of a function, or an LCEL runnable.\n",
        "\n",
        "If we were to think about edges in the context of LangGraph - we might think of them as \"paths to take\" or \"where to pass our state object next\".\n",
        "\n",
        "Let's create some nodes and expand on our diagram.\n",
        "\n",
        "> NOTE: Due to the tight integration with LCEL - we can comfortably create our nodes in an async fashion!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "91flJWtZLUrl"
      },
      "outputs": [],
      "source": [
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "def call_model(state):\n",
        "  messages = state[\"messages\"]\n",
        "  response = model.invoke(messages)\n",
        "  return {\"messages\" : [response]}\n",
        "\n",
        "tool_node = ToolNode(tool_belt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bwR7MgWj3Wg"
      },
      "source": [
        "Now we have two total nodes. We have:\n",
        "\n",
        "- `call_model` is a node that will...well...call the model\n",
        "- `tool_node` is a node which can call a tool\n",
        "\n",
        "Let's start adding nodes! We'll update our diagram along the way to keep track of what this looks like!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vF4_lgtmQNo",
        "outputId": "a4384377-8f7a-415f-be1b-fee6169cb101"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x119682510>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "uncompiled_graph = StateGraph(AgentState)\n",
        "\n",
        "uncompiled_graph.add_node(\"agent\", call_model)\n",
        "uncompiled_graph.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8CjRlbVmRpW"
      },
      "source": [
        "Let's look at what we have so far:\n",
        "\n",
        "![image](https://i.imgur.com/md7inqG.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaXHpPeSnOWC"
      },
      "source": [
        "Next, we'll add our entrypoint. All our entrypoint does is indicate which node is called first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGCbaYqRnmiw",
        "outputId": "5351807c-2ac7-4316-a3a3-878abeacd114"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x119682510>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsfGoSpoF9U"
      },
      "source": [
        "![image](https://i.imgur.com/wNixpJe.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q_pQgHmoW0M"
      },
      "source": [
        "Now we want to build a \"conditional edge\" which will use the output state of a node to determine which path to follow.\n",
        "\n",
        "We can help conceptualize this by thinking of our conditional edge as a conditional in a flowchart!\n",
        "\n",
        "Notice how our function simply checks if there is a \"function_call\" kwarg present.\n",
        "\n",
        "Then we create an edge where the origin node is our agent node and our destination node is *either* the action node or the END (finish the graph).\n",
        "\n",
        "It's important to highlight that the dictionary passed in as the third parameter (the mapping) should be created with the possible outputs of our conditional function in mind. In this case `should_continue` outputs either `\"end\"` or `\"continue\"` which are subsequently mapped to the action node or the END node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BZgb81VQf9o",
        "outputId": "73a07c15-5f0b-40f2-b033-38b57d056dd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x119682510>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def should_continue(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  return END\n",
        "\n",
        "uncompiled_graph.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    should_continue\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Cvhcf4jp0Ce"
      },
      "source": [
        "Let's visualize what this looks like.\n",
        "\n",
        "![image](https://i.imgur.com/8ZNwKI5.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKCjWJCkrJb9"
      },
      "source": [
        "Finally, we can add our last edge which will connect our action node to our agent node. This is because we *always* want our action node (which is used to call our tools) to return its output to our agent!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvcgbHf1rIXZ",
        "outputId": "45d4bdd6-d6bb-4a1d-bb79-cad43c130bf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x119682510>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "uncompiled_graph.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiWDwBQtrw7Z"
      },
      "source": [
        "Let's look at the final visualization.\n",
        "\n",
        "![image](https://i.imgur.com/NWO7usO.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYqDpErlsCsu"
      },
      "source": [
        "All that's left to do now is to compile our workflow - and we're off!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zt9-KS8DpzNx"
      },
      "outputs": [],
      "source": [
        "simple_agent_graph = uncompiled_graph.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhNWIwBL1W4Q"
      },
      "source": [
        "#### ‚ùì Question #2:\n",
        "\n",
        "Is there any specific limit to how many times we can cycle?\n",
        "\n",
        "If not, how could we impose a limit to the number of cycles?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ‚úÖ Answer: Yes, max_iterations is the parameter that limits the number of cycles. Default value is 15 (according to https://python.langchain.com/api_reference/langchain/agents/langchain.agents.agent.AgentExecutor.html) but can be overriden . \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "        word-wrap: break-word;\n",
              "        max-width: 100%;\n",
              "        overflow-x: hidden;\n",
              "    }\n",
              "    .output_area {\n",
              "        white-space: pre-wrap;\n",
              "        word-wrap: break-word;\n",
              "        max-width: 100%;\n",
              "        overflow-x: hidden;\n",
              "    }\n",
              "    .output_text {\n",
              "        white-space: pre-wrap;\n",
              "        word-wrap: break-word;\n",
              "    }\n",
              "    div.output {\n",
              "        white-space: pre-wrap;\n",
              "        word-wrap: break-word;\n",
              "        max-width: 100%;\n",
              "    }\n",
              "    span {\n",
              "        white-space: pre-wrap;\n",
              "        word-wrap: break-word;\n",
              "    }\n",
              "    </style>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import HTML, display\n",
        "def set_output_wrapping():\n",
        "    display(HTML('''\n",
        "    <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "        word-wrap: break-word;\n",
        "        max-width: 100%;\n",
        "        overflow-x: hidden;\n",
        "    }\n",
        "    .output_area {\n",
        "        white-space: pre-wrap;\n",
        "        word-wrap: break-word;\n",
        "        max-width: 100%;\n",
        "        overflow-x: hidden;\n",
        "    }\n",
        "    .output_text {\n",
        "        white-space: pre-wrap;\n",
        "        word-wrap: break-word;\n",
        "    }\n",
        "    div.output {\n",
        "        white-space: pre-wrap;\n",
        "        word-wrap: break-word;\n",
        "        max-width: 100%;\n",
        "    }\n",
        "    span {\n",
        "        white-space: pre-wrap;\n",
        "        word-wrap: break-word;\n",
        "    }\n",
        "    </style>\n",
        "    '''))\n",
        "set_output_wrapping()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEYcTShCsPaa"
      },
      "source": [
        "## Using Our Graph\n",
        "\n",
        "Now that we've created and compiled our graph - we can call it *just as we'd call any other* `Runnable`!\n",
        "\n",
        "Let's try out a few examples to see how it fairs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qn4n37PQRPII",
        "outputId": "5eeedfae-089d-496e-e71f-071939fa5832"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_LQRu0qjR0hwKTMAey7hOxkI1', 'function': {'arguments': '{\"query\": \"How are technical professionals using AI to improve their work?\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 213, 'total_tokens': 257, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHATskkCtIRtTYB5sRYUPsLYUJ48', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--51fde11c-bc4c-4838-83a2-36a7658f82e1-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'How are technical professionals using AI to improve their work?'}, 'id': 'call_LQRu0qjR0hwKTMAey7hOxkI1', 'type': 'tool_call'}], usage_metadata={'input_tokens': 213, 'output_tokens': 44, 'total_tokens': 257, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"The Impact of AI on the Engineering Field | JHU EP\", \"url\": \"https://ep.jhu.edu/news/the-impact-of-ai-on-the-engineering-field/\", \"content\": \"### Design Optimization\\\\n\\\\nFor engineers working with design professionals, AI can use advanced algorithms and simulations to identify optimal configurations, enhance product performance, and minimize costs for complex designs. This approach is ideal for the automotive and aerospace industries, where improving performance and minimizing costs are top priorities for manufacturers and consumers.\\\\n\\\\n### Autonomous Systems [...] Engineers already play an increasingly pivotal role in harnessing AI to tackle evolving global challenges and foster advancements in science and technology. Their expertise in understanding complex systems and domain-specific knowledge enables them to leverage AI tools for problem-solving and process optimization. By integrating AI into workflows, engineers deliver solutions that align with evolving technological landscapes. They‚Äôre then able to lead innovation across any field where [...] ### Collaboration Between AI Systems and Engineers\\\\n\\\\nEngineers are constantly finding new ways to incorporate AI into their work. Working with AI leads to increased productivity, efficiency, and creativity within a broad spectrum of engineering subfields. AI handles many of the repetitive tasks that can take up an engineer‚Äôs time. Engineers can then focus on higher-level decision-making, innovation, and problem-solving. \\\\n\\\\n## Engineering Careers in the AI Era\", \"score\": 0.56517935}, {\"title\": \"How to use agentic AI workflows in professional services\", \"url\": \"https://www.thomsonreuters.com/en/insights/articles/how-to-use-agentic-ai-workflows-in-professional-services\", \"content\": \"Boost productivity. By uniting research, analysis, and drafting in one platform, and not having to switch between tools, professionals can handle more tasks and also reallocate time for creative, human-centric work. [...] The momentum is building and AI is here to stay, but many professionals remain cautious. Agentic AI is often misunderstood as an advanced chatbot, or a replacement for GenAI, but it often works in combination with other technology, including GenAI, to plan and execute work. While generative AI responds to prompts by producing content such as text or images, agentic AI goes further ‚Äî it can make decisions, take actions, and adapt to changing environments and information with minimal human input. [...] Professional services industries, including those with specialized knowledge such as legal, tax, and risk organizations, are at a pivotal crossroads when it comes to artificial intelligence. Once familiar only to elite technology companies, AI has officially entered the mainstream and is proving useful across a spectrum of roles and industries. According to Gartner, more than 80% of enterprises will have used generative AI application programming interfaces (APIs) or deployed generative\", \"score\": 0.5439058}, {\"title\": \"AI in the workplace: Digital labor and the future of work\", \"url\": \"https://www.ibm.com/think/topics/ai-in-the-workplace\", \"content\": \"Generally, deploying AI in the workplace involves a wide ecosystem of technologies, the most common of which are:\\\\n\\\\n Machine learning: A branch of computer science that focuses on using algorithms to allow AI to imitate the way humans learn, gradually improving its functionality over time.\\\\n\\\\n Natural language processing (NLP): A form of AI that uses machine learning to understand and communicate in human language. [...] Organizations use AI in the workplace by deploying a wide range of technologies, including machine learning and natural language processing, that can mimic human intelligence to solve problems, make decisions and perform tasks traditionally handled by humans. AI can analyze data, recognize patterns, learn from experience and adapt over time. It is often used to streamline operations, enhance productivity, automate repetitive tasks and support decision-making. [...] AI is increasingly used to improve operational efficiency by automating workflows, optimizing resource allocation and enhancing productivity. AI-powered RPA tools automate repetitive tasks such as data entry, document processing and invoicing, reducing human error and allowing employees to focus on more strategic activities.\", \"score\": 0.5363378}, {\"title\": \"AI integration: How to bring AI into your workflows\", \"url\": \"https://zapier.com/blog/ai-integration/\", \"content\": \"Human resources teams might get AI-generated candidate summaries, parse resumes automatically, or onboard employees with AI-generated emails.\\\\n Engineering teams might use AIOps to analyze and interpret larger datasets, increase response times, and find root causes faster.\\\\n Ops teams might use AI to summarize, analyze, and even create charts from business data. [...] Marketing teams might use AI to speed up content production or automate AI image generation for social media posts.\\\\n Sales teams might build AI chatbots to nurture and qualify leads before adding them to a CRM.\\\\n Customer success teams might use AI to route and triage tickets intelligently, conduct sentiment analysis, and answer simpler, self-service questions through a website chatbot.\", \"score\": 0.493336}, {\"title\": \"Insights on Generative AI and the Future of Work | NC ...\", \"url\": \"https://www.commerce.nc.gov/news/the-lead-feed/generative-ai-and-future-work\", \"content\": \"## AI may be used to augment and improve work. [...] Thus, the integration of AI presents an opportunity to enhance the quality and efficiency of work across a multitude of sectors. By automating routine and mundane tasks, AI can potentially allow workers to focus on the core aspects of their roles that require human insight, creativity, and specialized skills.\\\\n\\\\n## AI may have positive impacts on productivity and democratization of skills. [...] Several studies have suggested AI may be beneficial for worker productivity across tasks like business writing, programming, customer support, and consulting. These studies compared groups with and without AI assistance on the number of tasks completed, time to complete tasks, and in some cases the quality of output. Notably, the most significant benefits in productivity were observed among less-experienced, lower-skilled workers, although AI tended to improve performance for all.\", \"score\": 0.41406992}]', name='tavily_search_results_json', id='4f587809-e492-45cc-ab10-426a2da7d92e', tool_call_id='call_LQRu0qjR0hwKTMAey7hOxkI1', artifact={'query': 'How are technical professionals using AI to improve their work?', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://ep.jhu.edu/news/the-impact-of-ai-on-the-engineering-field/', 'title': 'The Impact of AI on the Engineering Field | JHU EP', 'content': '### Design Optimization\\n\\nFor engineers working with design professionals, AI can use advanced algorithms and simulations to identify optimal configurations, enhance product performance, and minimize costs for complex designs. This approach is ideal for the automotive and aerospace industries, where improving performance and minimizing costs are top priorities for manufacturers and consumers.\\n\\n### Autonomous Systems [...] Engineers already play an increasingly pivotal role in harnessing AI to tackle evolving global challenges and foster advancements in science and technology. Their expertise in understanding complex systems and domain-specific knowledge enables them to leverage AI tools for problem-solving and process optimization. By integrating AI into workflows, engineers deliver solutions that align with evolving technological landscapes. They‚Äôre then able to lead innovation across any field where [...] ### Collaboration Between AI Systems and Engineers\\n\\nEngineers are constantly finding new ways to incorporate AI into their work. Working with AI leads to increased productivity, efficiency, and creativity within a broad spectrum of engineering subfields. AI handles many of the repetitive tasks that can take up an engineer‚Äôs time. Engineers can then focus on higher-level decision-making, innovation, and problem-solving. \\n\\n## Engineering Careers in the AI Era', 'score': 0.56517935, 'raw_content': None}, {'url': 'https://www.thomsonreuters.com/en/insights/articles/how-to-use-agentic-ai-workflows-in-professional-services', 'title': 'How to use agentic AI workflows in professional services', 'content': 'Boost productivity. By uniting research, analysis, and drafting in one platform, and not having to switch between tools, professionals can handle more tasks and also reallocate time for creative, human-centric work. [...] The momentum is building and AI is here to stay, but many professionals remain cautious. Agentic AI is often misunderstood as an advanced chatbot, or a replacement for GenAI, but it often works in combination with other technology, including GenAI, to plan and execute work. While generative AI responds to prompts by producing content such as text or images, agentic AI goes further ‚Äî it can make decisions, take actions, and adapt to changing environments and information with minimal human input. [...] Professional services industries, including those with specialized knowledge such as legal, tax, and risk organizations, are at a pivotal crossroads when it comes to artificial intelligence. Once familiar only to elite technology companies, AI has officially entered the mainstream and is proving useful across a spectrum of roles and industries. According to Gartner, more than 80% of enterprises will have used generative AI application programming interfaces (APIs) or deployed generative', 'score': 0.5439058, 'raw_content': None}, {'url': 'https://www.ibm.com/think/topics/ai-in-the-workplace', 'title': 'AI in the workplace: Digital labor and the future of work', 'content': 'Generally, deploying AI in the workplace involves a wide ecosystem of technologies, the most common of which are:\\n\\n Machine learning: A branch of computer science that focuses on using algorithms to allow AI to imitate the way humans learn, gradually improving its functionality over time.\\n\\n Natural language processing (NLP): A form of AI that uses machine learning to understand and communicate in human language. [...] Organizations use AI in the workplace by deploying a wide range of technologies, including machine learning and natural language processing, that can mimic human intelligence to solve problems, make decisions and perform tasks traditionally handled by humans. AI can analyze data, recognize patterns, learn from experience and adapt over time. It is often used to streamline operations, enhance productivity, automate repetitive tasks and support decision-making. [...] AI is increasingly used to improve operational efficiency by automating workflows, optimizing resource allocation and enhancing productivity. AI-powered RPA tools automate repetitive tasks such as data entry, document processing and invoicing, reducing human error and allowing employees to focus on more strategic activities.', 'score': 0.5363378, 'raw_content': None}, {'url': 'https://zapier.com/blog/ai-integration/', 'title': 'AI integration: How to bring AI into your workflows', 'content': 'Human resources teams might get AI-generated candidate summaries, parse resumes automatically, or onboard employees with AI-generated emails.\\n Engineering teams might use AIOps to analyze and interpret larger datasets, increase response times, and find root causes faster.\\n Ops teams might use AI to summarize, analyze, and even create charts from business data. [...] Marketing teams might use AI to speed up content production or automate AI image generation for social media posts.\\n Sales teams might build AI chatbots to nurture and qualify leads before adding them to a CRM.\\n Customer success teams might use AI to route and triage tickets intelligently, conduct sentiment analysis, and answer simpler, self-service questions through a website chatbot.', 'score': 0.493336, 'raw_content': None}, {'url': 'https://www.commerce.nc.gov/news/the-lead-feed/generative-ai-and-future-work', 'title': 'Insights on Generative AI and the Future of Work | NC ...', 'content': '## AI may be used to augment and improve work. [...] Thus, the integration of AI presents an opportunity to enhance the quality and efficiency of work across a multitude of sectors. By automating routine and mundane tasks, AI can potentially allow workers to focus on the core aspects of their roles that require human insight, creativity, and specialized skills.\\n\\n## AI may have positive impacts on productivity and democratization of skills. [...] Several studies have suggested AI may be beneficial for worker productivity across tasks like business writing, programming, customer support, and consulting. These studies compared groups with and without AI assistance on the number of tasks completed, time to complete tasks, and in some cases the quality of output. Notably, the most significant benefits in productivity were observed among less-experienced, lower-skilled workers, although AI tended to improve performance for all.', 'score': 0.41406992, 'raw_content': None}], 'response_time': 3.2, 'request_id': '44d56508-eaef-4067-abda-a67513fe0b89'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Technical professionals are leveraging AI in various ways to enhance their work. Some of the key applications include:\\n\\n1. Design Optimization: Engineers use AI algorithms and simulations to identify optimal configurations, improve product performance, and reduce costs, especially in automotive and aerospace industries.\\n2. Automation of Repetitive Tasks: AI handles routine tasks such as data entry, document processing, and analysis, freeing up professionals to focus on higher-level decision-making, innovation, and problem-solving.\\n3. Advanced Data Analysis: AI tools like AIOps analyze large datasets, identify patterns, and help in troubleshooting and root cause analysis, particularly in engineering and IT fields.\\n4. Decision-Making and Workflow Automation: AI systems, including natural language processing and machine learning, assist in decision-making, automate workflows, and optimize resource allocation.\\n5. Content Creation and Communication: In marketing and professional services, AI speeds up content production, automates image generation, and helps in drafting and summarizing information.\\n6. Enhancing Productivity and Skills: AI augments work by improving efficiency, democratizing skills, and enabling workers to focus on creative and strategic tasks, especially benefiting less-experienced workers.\\n7. Integration into Workflows: Professionals are incorporating AI into various functions such as HR, engineering, operations, sales, and customer support to streamline processes and improve outcomes.\\n\\nOverall, AI is seen as a tool to increase productivity, foster innovation, and enable professionals to focus on complex and creative aspects of their work.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 296, 'prompt_tokens': 1485, 'total_tokens': 1781, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHAY1wHahIEmVNFKbbNEXxiG7nHn', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--7cb3835b-cc34-4923-96c5-1b22eb27ea29-0', usage_metadata={'input_tokens': 1485, 'output_tokens': 296, 'total_tokens': 1781, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "import sys\n",
        "\n",
        "inputs = {\"messages\" : [HumanMessage(content=\"How are technical professionals using AI to improve their work?\")]}\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBHnUtLSscRr"
      },
      "source": [
        "Let's look at what happened:\n",
        "\n",
        "1. Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node added an `AIMessage` to the state object and passed it along the conditional edge\n",
        "3. The conditional edge received the state object, found the \"tool_calls\" `additional_kwarg`, and sent the state object to the action node\n",
        "4. The action node added the response from the OpenAI function calling endpoint to the state object and passed it along the edge to the agent node\n",
        "5. The agent node added a response to the state object and passed it along the conditional edge\n",
        "6. The conditional edge received the state object, could not find the \"tool_calls\" `additional_kwarg` and passed the state object to END where we see it output in the cell above!\n",
        "\n",
        "Now let's look at an example that shows a multiple tool usage - all with the same flow!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afv2BuEsV5JG",
        "outputId": "ff009536-d281-4a56-c126-9cd245352bfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_mCopQeuXQe6mAl4cFc0HODLx', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_A8ZpRPBOhSft80ftgeVxBsH2', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research paper\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 232, 'total_tokens': 291, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHAeU9oTkrIFOtgdAvFHNOUXjXNZ', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8f274f47-f473-4adc-b97f-4ee48bf3dd17-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_mCopQeuXQe6mAl4cFc0HODLx', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'A Comprehensive Survey of Deep Research paper'}, 'id': 'call_A8ZpRPBOhSft80ftgeVxBsH2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 232, 'output_tokens': 59, 'total_tokens': 291, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='a2a4961b-657d-485a-a09c-36e2da1cd786', tool_call_id='call_mCopQeuXQe6mAl4cFc0HODLx'), ToolMessage(content='[{\"title\": \"A Comprehensive Survey of Deep Learning for Time ...\", \"url\": \"https://arxiv.org/abs/2411.05793\", \"content\": \"From: Hyungjoon Kim [view email] (/abs/2411.05793v1) Thu, 24 Oct 2024 07:43:55 UTC (1,438 KB) (/abs/2411.05793v2) Fri, 21 Mar 2025 01:49:26 UTC (1,438 KB) [v3] Thu, 1 May 2025 05:05:29 UTC (1,592 KB)\\\\n\\\\nFull-text links:\\\\n\\\\n## Access Paper:\\\\n\\\\nView a PDF of the paper titled A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges, by Jongseon Kim and 4 other authors\\\\n\\\\n View PDF\\\\n HTML (experimental)\\\\n TeX Source\\\\n Other Formats\\\\n\\\\nview license [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\\\n\\\\n> cs > arXiv:2411.05793\\\\n\\\\n# Computer Science > Machine Learning\\\\n\\\\narXiv:2411.05793 (cs)\\\\n\\\\nSubmitted on 24 Oct 2024 ([v1), last revised 1 May 2025 (this version, v3)]\\\\n\\\\n# Title:A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges\\\\n\\\\nAuthors:Jongseon Kim, Hyungjoon Kim, HyunGi Kim, Dongjun Lee, Sungroh Yoon [...] View a PDF of the paper titled A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges, by Jongseon Kim and 4 other authors\", \"score\": 0.76701033}, {\"title\": \"A comprehensive survey of deep learning research on ...\", \"url\": \"https://pubmed.ncbi.nlm.nih.gov/36462229/\", \"content\": \"Access keysNCBI HomepageMyNCBI HomepageMain ContentMain Navigation\\\\n\\\\n\\\\n\\\\n Search:  Search\\\\n\\\\nAdvancedClipboard\\\\n\\\\nUser Guide\\\\n\\\\n Save  Email \\\\n\\\\nSend to\\\\n\\\\n   Clipboard\\\\n   My Bibliography\\\\n   Collections\\\\n   Citation manager\\\\n\\\\nDisplay options\\\\n\\\\n Display options \\\\n\\\\n Format \\\\n\\\\nSave citation to file\\\\n\\\\n Format:  \\\\n\\\\n Create file  Cancel \\\\n\\\\nEmail citation\\\\n\\\\n Email address has not been verified. Go to My NCBI account settings to confirm your email and then refresh this page. \\\\n\\\\n To: \\\\n\\\\n Subject:  \\\\n\\\\n Body:  \\\\n\\\\n Format: [...] PMID: 36462229\\\\n    DOI: 10.1016/j.clinimag.2022.11.003\\\\n\\\\n Item in Clipboard \\\\n\\\\nReview\\\\n\\\\nA comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\\\n\\\\nSema Atasever et al. Clin Imaging.2023 Feb.\\\\n\\\\nShow details\\\\n\\\\nDisplay options\\\\n\\\\n Display options \\\\n\\\\n Format \\\\n\\\\n Clin Imaging \\\\n\\\\nActions\\\\n\\\\n   Search in PubMed\\\\n   Search in NLM Catalog\\\\n   Add to Search\\\\n\\\\n. 2023 Feb:94:18-41.\\\\n\\\\n doi: 10.1016/j.clinimag.2022.11.003.  Epub 2022 Nov 12. \\\\n\\\\n### Authors [...] PMID: 36462229\\\\n    DOI: 10.1016/j.clinimag.2022.11.003\\\\n\\\\n Item in Clipboard \\\\n\\\\n Full text links Cite\\\\n\\\\nDisplay options\\\\n\\\\n Display options \\\\n\\\\n Format \\\\n\\\\nAbstract\", \"score\": 0.7144891}, {\"title\": \"A Comprehensive Survey of Deep Learning Approaches in ...\", \"url\": \"https://www.mdpi.com/1424-8220/25/2/531\", \"content\": \"Elias Dritsas\\\\n\\\\nElias Dritsas\\\\n\\\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\\\n\\\\n \\\\\\\\\\\\n\\\\nIndustrial Systems Institute (ISI), Athena Research and Innovation Center, 26504 Patras, Greece\\\\n\\\\n\\\\\\\\\\\\n\\\\nAuthor to whom correspondence should be addressed.\\\\n\\\\nSensors 2025, 25(2), 531; \\\\n\\\\nSubmission received: 20 December 2024 / Revised: 13 January 2025 / Accepted: 13 January 2025 / Published: 17 January 2025 [...] Visit our dedicated information section to learn more about MDPI.\\\\n\\\\n Get Information\\\\n\\\\nclear\\\\n\\\\n## JSmol Viewer\\\\n\\\\nclear\\\\n\\\\nfirst\\\\\\\\_page\\\\n\\\\n Download PDF \\\\n\\\\nsettings\\\\n\\\\n Order Article Reprints\\\\n\\\\nFont Type:\\\\n\\\\nArial Georgia Verdana\\\\n\\\\nFont Size:\\\\n\\\\nAa Aa Aa\\\\n\\\\nLine Spacing:\\\\n\\\\n\\uf034   \\uf034   \\uf034\\\\n\\\\nColumn Width:\\\\n\\\\n\\uf035   \\uf035   \\uf035\\\\n\\\\nBackground:\\\\n\\\\nOpen AccessReview\\\\n\\\\n# A Comprehensive Survey of Deep Learning Approaches in Image Processing\\\\n\\\\nby \\\\n\\\\nMaria Trigka\\\\n\\\\nMaria Trigka\\\\n\\\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\\\n\\\\nand [...] The rapid advancements and widespread adoption of DL in image processing have led to an explosion of research, resulting in a vast and fragmented body of knowledge. As new models and techniques continuously emerge, it becomes increasingly challenging for researchers and practitioners to stay abreast of the latest developments and to understand how these advancements interrelate. This survey is motivated by the need to consolidate and synthesize this growing body of work, providing a structured\", \"score\": 0.6016175}, {\"title\": \"A Comprehensive Survey on Deep Learning Techniques in ...\", \"url\": \"https://arxiv.org/html/2309.04761v3\", \"content\": \"ùê° v(t)=‚àëu‚ààN\\u2062(v)f\\u2062(ùêó v,ùêó(v,u)ùêû,ùêó u,ùê° u(t‚àí1)),subscript superscript ùê° ùë° ùë£ subscript ùë¢ ùëÅ ùë£ ùëì subscript ùêó ùë£ superscript subscript ùêó ùë£ ùë¢ ùêû subscript ùêó ùë¢ superscript subscript ùê° ùë¢ ùë° 1\\\\\\\\mathbf{h}^{(t)}_{v}=\\\\\\\\sum_{u\\\\\\\\in N(v)}f(\\\\\\\\mathbf{X}_{v},\\\\\\\\mathbf{X}_{(v,u)}^{% \\\\\\\\mathbf{e}},\\\\\\\\mathbf{X}_{u},\\\\\\\\mathbf{h}_{u}^{(t-1)}),bold_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT = ‚àë start_POSTSUBSCRIPT italic_u ‚àà italic_N ( italic_v ) end_POSTSUBSCRIPT italic_f ( [...] L D=‚àí[log\\u2061(D\\u2062(x))+log\\u2061(1‚àíD\\u2062(G\\u2062(z)))]L G=‚àílog\\u2061(D\\u2062(G\\u2062(z))),subscript ùêø ùê∑ delimited-[]ùê∑ ùë• 1 ùê∑ ùê∫ ùëß subscript ùêø ùê∫ ùê∑ ùê∫ ùëß\\\\\\\\begin{split}L_{D}&=-[\\\\\\\\log(D(x))+\\\\\\\\log(1-D(G(z)))]\\\\\\\\\\\\\\\\ L_{G}&=-\\\\\\\\log(D(G(z))),\\\\\\\\end{split}start_ROW start_CELL italic_L start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT end_CELL start_CELL = - [ roman_log ( italic_D ( italic_x ) ) + roman_log ( 1 - italic_D ( italic_G ( italic_z ) ) ) ] end_CELL end_ROW start_ROW start_CELL italic_L start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT end_CELL [...] h t=œÉ\\u2062(W i\\u2062h\\u2062x t+W h\\u2062h\\u2062h t‚àí1+b h),subscript ‚Ñé ùë° ùúé subscript ùëä ùëñ ‚Ñé subscript ùë• ùë° subscript ùëä ‚Ñé ‚Ñé subscript ‚Ñé ùë° 1 subscript ùëè ‚Ñé h_{t}=\\\\\\\\sigma(W_{ih}x_{t}+W_{hh}h_{t-1}+b_{h}),italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_œÉ ( italic_W start_POSTSUBSCRIPT italic_i italic_h end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_h end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b\", \"score\": 0.5697814}, {\"title\": \"A comprehensive survey of deep learning research on ...\", \"url\": \"https://www.sciencedirect.com/science/article/abs/pii/S0899707122002856\", \"content\": \"Skip to main contentSkip to article\\\\n\\\\nSign in\\\\n\\\\n Access through your organization\\\\n Purchase PDF\\\\n Patient Access\\\\n\\\\nWe use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. You can manage your cookie preferences using the ‚ÄúCookie Settings‚Äù link. For more information, see ourCookie Policy\\\\n\\\\n## Cookie Preference Center [...] We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our Cookie Policy and the list of Google Ad-Tech Vendors. [...] You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.\\\\n  \\\\n  \\\\nYou may also be able to exercise your privacy choices as described in our Privacy Policy\", \"score\": 0.5550741}]', name='tavily_search_results_json', id='fa53eac8-6294-432f-bab2-988b52e8032d', tool_call_id='call_A8ZpRPBOhSft80ftgeVxBsH2', artifact={'query': 'A Comprehensive Survey of Deep Research paper', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/abs/2411.05793', 'title': 'A Comprehensive Survey of Deep Learning for Time ...', 'content': 'From: Hyungjoon Kim [view email] (/abs/2411.05793v1) Thu, 24 Oct 2024 07:43:55 UTC (1,438 KB) (/abs/2411.05793v2) Fri, 21 Mar 2025 01:49:26 UTC (1,438 KB) [v3] Thu, 1 May 2025 05:05:29 UTC (1,592 KB)\\n\\nFull-text links:\\n\\n## Access Paper:\\n\\nView a PDF of the paper titled A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges, by Jongseon Kim and 4 other authors\\n\\n View PDF\\n HTML (experimental)\\n TeX Source\\n Other Formats\\n\\nview license [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:2411.05793\\n\\n# Computer Science > Machine Learning\\n\\narXiv:2411.05793 (cs)\\n\\nSubmitted on 24 Oct 2024 ([v1), last revised 1 May 2025 (this version, v3)]\\n\\n# Title:A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges\\n\\nAuthors:Jongseon Kim, Hyungjoon Kim, HyunGi Kim, Dongjun Lee, Sungroh Yoon [...] View a PDF of the paper titled A Comprehensive Survey of Deep Learning for Time Series Forecasting: Architectural Diversity and Open Challenges, by Jongseon Kim and 4 other authors', 'score': 0.76701033, 'raw_content': None}, {'url': 'https://pubmed.ncbi.nlm.nih.gov/36462229/', 'title': 'A comprehensive survey of deep learning research on ...', 'content': 'Access keysNCBI HomepageMyNCBI HomepageMain ContentMain Navigation\\n\\n\\n\\n Search:  Search\\n\\nAdvancedClipboard\\n\\nUser Guide\\n\\n Save  Email \\n\\nSend to\\n\\n   Clipboard\\n   My Bibliography\\n   Collections\\n   Citation manager\\n\\nDisplay options\\n\\n Display options \\n\\n Format \\n\\nSave citation to file\\n\\n Format:  \\n\\n Create file  Cancel \\n\\nEmail citation\\n\\n Email address has not been verified. Go to My NCBI account settings to confirm your email and then refresh this page. \\n\\n To: \\n\\n Subject:  \\n\\n Body:  \\n\\n Format: [...] PMID: 36462229\\n    DOI: 10.1016/j.clinimag.2022.11.003\\n\\n Item in Clipboard \\n\\nReview\\n\\nA comprehensive survey of deep learning research on medical image analysis with focus on transfer learning\\n\\nSema Atasever et al. Clin Imaging.2023 Feb.\\n\\nShow details\\n\\nDisplay options\\n\\n Display options \\n\\n Format \\n\\n Clin Imaging \\n\\nActions\\n\\n   Search in PubMed\\n   Search in NLM Catalog\\n   Add to Search\\n\\n. 2023 Feb:94:18-41.\\n\\n doi: 10.1016/j.clinimag.2022.11.003.  Epub 2022 Nov 12. \\n\\n### Authors [...] PMID: 36462229\\n    DOI: 10.1016/j.clinimag.2022.11.003\\n\\n Item in Clipboard \\n\\n Full text links Cite\\n\\nDisplay options\\n\\n Display options \\n\\n Format \\n\\nAbstract', 'score': 0.7144891, 'raw_content': None}, {'url': 'https://www.mdpi.com/1424-8220/25/2/531', 'title': 'A Comprehensive Survey of Deep Learning Approaches in ...', 'content': 'Elias Dritsas\\n\\nElias Dritsas\\n\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\n\\n \\\\\\n\\nIndustrial Systems Institute (ISI), Athena Research and Innovation Center, 26504 Patras, Greece\\n\\n\\\\\\n\\nAuthor to whom correspondence should be addressed.\\n\\nSensors 2025, 25(2), 531; \\n\\nSubmission received: 20 December 2024 / Revised: 13 January 2025 / Accepted: 13 January 2025 / Published: 17 January 2025 [...] Visit our dedicated information section to learn more about MDPI.\\n\\n Get Information\\n\\nclear\\n\\n## JSmol Viewer\\n\\nclear\\n\\nfirst\\\\_page\\n\\n Download PDF \\n\\nsettings\\n\\n Order Article Reprints\\n\\nFont Type:\\n\\nArial Georgia Verdana\\n\\nFont Size:\\n\\nAa Aa Aa\\n\\nLine Spacing:\\n\\n\\uf034   \\uf034   \\uf034\\n\\nColumn Width:\\n\\n\\uf035   \\uf035   \\uf035\\n\\nBackground:\\n\\nOpen AccessReview\\n\\n# A Comprehensive Survey of Deep Learning Approaches in Image Processing\\n\\nby \\n\\nMaria Trigka\\n\\nMaria Trigka\\n\\nSciProfiles  Scilit  Preprints.org  Google Scholar\\n\\nand [...] The rapid advancements and widespread adoption of DL in image processing have led to an explosion of research, resulting in a vast and fragmented body of knowledge. As new models and techniques continuously emerge, it becomes increasingly challenging for researchers and practitioners to stay abreast of the latest developments and to understand how these advancements interrelate. This survey is motivated by the need to consolidate and synthesize this growing body of work, providing a structured', 'score': 0.6016175, 'raw_content': None}, {'url': 'https://arxiv.org/html/2309.04761v3', 'title': 'A Comprehensive Survey on Deep Learning Techniques in ...', 'content': 'ùê° v(t)=‚àëu‚ààN\\u2062(v)f\\u2062(ùêó v,ùêó(v,u)ùêû,ùêó u,ùê° u(t‚àí1)),subscript superscript ùê° ùë° ùë£ subscript ùë¢ ùëÅ ùë£ ùëì subscript ùêó ùë£ superscript subscript ùêó ùë£ ùë¢ ùêû subscript ùêó ùë¢ superscript subscript ùê° ùë¢ ùë° 1\\\\mathbf{h}^{(t)}_{v}=\\\\sum_{u\\\\in N(v)}f(\\\\mathbf{X}_{v},\\\\mathbf{X}_{(v,u)}^{% \\\\mathbf{e}},\\\\mathbf{X}_{u},\\\\mathbf{h}_{u}^{(t-1)}),bold_h start_POSTSUPERSCRIPT ( italic_t ) end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT = ‚àë start_POSTSUBSCRIPT italic_u ‚àà italic_N ( italic_v ) end_POSTSUBSCRIPT italic_f ( [...] L D=‚àí[log\\u2061(D\\u2062(x))+log\\u2061(1‚àíD\\u2062(G\\u2062(z)))]L G=‚àílog\\u2061(D\\u2062(G\\u2062(z))),subscript ùêø ùê∑ delimited-[]ùê∑ ùë• 1 ùê∑ ùê∫ ùëß subscript ùêø ùê∫ ùê∑ ùê∫ ùëß\\\\begin{split}L_{D}&=-[\\\\log(D(x))+\\\\log(1-D(G(z)))]\\\\\\\\ L_{G}&=-\\\\log(D(G(z))),\\\\end{split}start_ROW start_CELL italic_L start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT end_CELL start_CELL = - [ roman_log ( italic_D ( italic_x ) ) + roman_log ( 1 - italic_D ( italic_G ( italic_z ) ) ) ] end_CELL end_ROW start_ROW start_CELL italic_L start_POSTSUBSCRIPT italic_G end_POSTSUBSCRIPT end_CELL [...] h t=œÉ\\u2062(W i\\u2062h\\u2062x t+W h\\u2062h\\u2062h t‚àí1+b h),subscript ‚Ñé ùë° ùúé subscript ùëä ùëñ ‚Ñé subscript ùë• ùë° subscript ùëä ‚Ñé ‚Ñé subscript ‚Ñé ùë° 1 subscript ùëè ‚Ñé h_{t}=\\\\sigma(W_{ih}x_{t}+W_{hh}h_{t-1}+b_{h}),italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_œÉ ( italic_W start_POSTSUBSCRIPT italic_i italic_h end_POSTSUBSCRIPT italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_h end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b', 'score': 0.5697814, 'raw_content': None}, {'url': 'https://www.sciencedirect.com/science/article/abs/pii/S0899707122002856', 'title': 'A comprehensive survey of deep learning research on ...', 'content': 'Skip to main contentSkip to article\\n\\nSign in\\n\\n Access through your organization\\n Purchase PDF\\n Patient Access\\n\\nWe use cookies that are necessary to make our site work. We may also use additional cookies to analyze, improve, and personalize our content and your digital experience. You can manage your cookie preferences using the ‚ÄúCookie Settings‚Äù link. For more information, see ourCookie Policy\\n\\n## Cookie Preference Center [...] We use cookies which are necessary to make our site work. We may also use additional cookies to analyse, improve and personalise our content and your digital experience. For more information, see our Cookie Policy and the list of Google Ad-Tech Vendors. [...] You may choose not to allow some types of cookies. However, blocking some types may impact your experience of our site and the services we are able to offer. See the different category headings below to find out more or change your settings.\\n  \\n  \\nYou may also be able to exercise your privacy choices as described in our Privacy Policy', 'score': 0.5550741, 'raw_content': None}], 'response_time': 2.61, 'request_id': '8fed48ed-7c80-4fd0-b7fc-aeec8ae633d2'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='I found the research paper titled \"A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\" published in 2025 by authors Renjun Xu and Jingwen Peng. \\n\\nNow, I will search for each of the authors to find out where they currently work.', additional_kwargs={'tool_calls': [{'id': 'call_oAw1sZ0WqYe03eNLBpTvxim9', 'function': {'arguments': '{\"query\": \"Renjun Xu\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_tthF5zAGFBjy8VcpobOmGRfV', 'function': {'arguments': '{\"query\": \"Jingwen Peng\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 114, 'prompt_tokens': 3458, 'total_tokens': 3572, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHAjCpWYZP7DN4wlzyNOzNxAvwtz', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--e3e4e797-7e8d-42d1-92e2-079f10ca1794-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Renjun Xu'}, 'id': 'call_oAw1sZ0WqYe03eNLBpTvxim9', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'Jingwen Peng'}, 'id': 'call_tthF5zAGFBjy8VcpobOmGRfV', 'type': 'tool_call'}], usage_metadata={'input_tokens': 3458, 'output_tokens': 114, 'total_tokens': 3572, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"Renjun Xu - Researcher, Zhejiang University - OpenReview\", \"url\": \"https://openreview.net/profile?id=~Renjun_Xu1\", \"content\": \"# Renjun Xu\\\\n\\\\n### Principal Researcher, Zhejiang University\\\\n\\\\n Joined September 2021\\\\n\\\\n#### Names\\\\n\\\\nRenjun Xu (Preferred)\\\\n\\\\n Suggest Name\\\\n\\\\n#### Emails\\\\n\\\\n\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\\\n\\\\n Suggest Email\\\\n\\\\n#### Personal Links\\\\n\\\\nHomepage\\\\n\\\\nDBLP\\\\n\\\\nORCID\\\\n\\\\nSemantic Scholar\\\\n\\\\n Suggest URL\\\\n\\\\n#### Career & Education History\\\\n\\\\nPrincipal Researcher\\\\n\\\\nZhejiang University(zju.edu.cn)\\\\n\\\\n2018 ‚Äì Present\\\\n\\\\n Suggest Position\\\\n\\\\n#### Advisors, Relations & Conflicts\\\\n\\\\nNo relations added\\\\n\\\\n Suggest Relation\\\\n\\\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\\\n\\\\nPresent\\\\n\\\\n Suggest Expertise\", \"score\": 0.7154444}, {\"title\": \"Renjun Xu - Center for Data Science, Zhejiang University\", \"url\": \"https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1\", \"content\": \"Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\\\n\\\\n\\\\n\\\\nResearch\\\\n\\\\nCenter for Data Science Zhejiang University\\\\n\\\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\\\n\\\\nEducation\\\\n\\\\nSign in to view more\\\\n\\\\nExperience\\\\n\\\\nSign in to view more [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\\\n\\\\nSwipe to Fine Result [...] Research Interests\\\\n\\\\n2012 2025\\\\n\\\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\\\n\\\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\\\n\\\\nÊó∂Èó¥\\\\n\\\\nÂºïÁî®Èáè\\\\n\\\\n‰∏ªÈ¢ò\\\\n\\\\nÊúüÂàäÁ∫ßÂà´\\\\n\\\\nÂêà‰ΩúËÄÖ\\\\n\\\\nÂêà‰ΩúÊú∫ÊûÑ\\\\n\\\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\\\n\\\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\\\n\\\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\\\n\\\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\\\n\\\\nCited 0 Views 11 Bibtex\\\\n\\\\n0\\\\n\\\\n11\", \"score\": 0.6030211}, {\"title\": \"Renjun Hu\\'s Homepage\", \"url\": \"https://hurenjun.github.io/\", \"content\": \"various business domains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge. Since January 2025, he has joined the School of Data Science and Engineering, East China Normal University as a young researcher. His recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor\\'s degree in 2014 and Ph.D. in 2020 from the School of Computer Science and Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student in the Data Mining Group at Rutgers University. He then worked as a research intern at the Business Intelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across [...] Young Researcher, East China Normal University, January 2025 - present\\\\n Algorithm engineer, Alibaba Group, July 2020 - January 2025\\\\n Research intern, Baidu Business Intelligence Lab, May 2018 - September 2019\\\\n Visiting student, Rutgers University, September 2017 - April 2018\", \"score\": 0.5760895}, {\"title\": \"RENJUN/Facts - NCT Wiki - Fandom\", \"url\": \"https://smtown-nctzens.fandom.com/wiki/RENJUN/Facts\", \"content\": \"He has a birthmark on the back of his hand\\\\n He used to have a snaggletooth back in 2016\\\\n He had/has lingual braces\\\\n He is one of the shortest members of NCT\\\\n He has a small dimple\\\\n\\\\n## Nicknames[]\\\\n\\\\n Golden Hands\\\\n Injeolmi\\\\n Injun (In-Joon)\\\\n JunJun\\\\n King of Losing\\\\n Moomin Otaku\\\\n Paper Doll/Man\\\\n Pure Boy\\\\n Shoulder Gangster\\\\n The One Who Brightens The World\\\\n The Prince of China\\\\n\\\\n## Relationships[] [...] Passed an online audition to SM Entertainment and got called the day before the actual audition date and so he talked to his parents and took a 3-hour train ride the next morning for the auditions and passed. RENJUN was accepted because of his dancing skills but after training, he became one of the main vocalists of NCT.\\\\n\\\\n## Personality[]\\\\n\\\\n## Appearance[] [...] RENJUN was a trainee for 1 year.\\\\n  + He was accepted to SM Entertainment through the 2015 Shenyang SM Global Audition, China in July.\\\\n  + RENJUN joined in 2015 and debuted in 2016.\\\\n He was announced as a NCT member in August 2016.\\\\n When watching the reality show, K-pop Star, RENJUN was indecisive on which company to audition to between SM, YG, and JYP. However, once he saw EXO, he decided to audition for SM\\'s Global Audition when he was 15 years old.\\\\n\\\\n#### Casting story[]\", \"score\": 0.49260366}, {\"title\": \"40+ \\\\\"Renjun Xu\\\\\" profiles\", \"url\": \"https://www.linkedin.com/pub/dir/Renjun/Xu\", \"content\": \"Sign Up | LinkedIn \\\\n\\\\nAgree & Join LinkedIn\\\\n\\\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\\\n\\\\nSkip to main contentLinkedIn\\\\n\\\\nJoin LinkedIn\\\\n\\\\nImage 1: Profile photo Not you? \\\\n\\\\n Remove photo \\\\n\\\\nFirst name \\\\n\\\\nLast name \\\\n\\\\nEmail \\\\n\\\\nPassword (6+ characters) \\\\n\\\\nBy clicking Agree & Join, you agree to the LinkedIn User Agreement, Privacy Policy, and Cookie Policy.\\\\n\\\\n Agree & Join \\\\n\\\\nor\\\\n\\\\nAlready on Linkedin?  Sign in\\\\n\\\\nSecurity verification [...] Sign in\\\\n\\\\n Email or phone  \\\\n\\\\n Password  \\\\n\\\\nShow\\\\n\\\\nForgot password? Sign in \\\\n\\\\nor\\\\n\\\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\\\n\\\\nNew to Linkedin?  Join now [...] ‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi) \\\\n        Magyar (Hungarian) \\\\n        Bahasa Indonesia (Indonesian) \\\\n        Italiano (Italian) \\\\n        ◊¢◊ë◊®◊ô◊™ (Hebrew) \\\\n        Êó•Êú¨Ë™û (Japanese) \\\\n        ÌïúÍµ≠Ïñ¥ (Korean) \\\\n        ‡§Æ‡§∞‡§æ‡§†‡•Ä (Marathi) \\\\n        Bahasa Malaysia (Malay) \\\\n        Nederlands (Dutch) \\\\n        Norsk (Norwegian) \\\\n        ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä (Punjabi) \\\\n        Polski (Polish) \\\\n        Portugu√™s (Portuguese) \\\\n        Rom√¢nƒÉ (Romanian) \\\\n        –†—É—Å—Å–∫–∏–π (Russian) \\\\n        Svenska (Swedish) \\\\n        ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)\", \"score\": 0.48879638}]', name='tavily_search_results_json', id='2c81786a-21a2-491e-b88d-9c6a944819c2', tool_call_id='call_oAw1sZ0WqYe03eNLBpTvxim9', artifact={'query': 'Renjun Xu', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://openreview.net/profile?id=~Renjun_Xu1', 'title': 'Renjun Xu - Researcher, Zhejiang University - OpenReview', 'content': '# Renjun Xu\\n\\n### Principal Researcher, Zhejiang University\\n\\n Joined September 2021\\n\\n#### Names\\n\\nRenjun Xu (Preferred)\\n\\n Suggest Name\\n\\n#### Emails\\n\\n\\\\\\\\\\\\\\\\@zju.edu.cn (Confirmed)\\n\\n Suggest Email\\n\\n#### Personal Links\\n\\nHomepage\\n\\nDBLP\\n\\nORCID\\n\\nSemantic Scholar\\n\\n Suggest URL\\n\\n#### Career & Education History\\n\\nPrincipal Researcher\\n\\nZhejiang University(zju.edu.cn)\\n\\n2018 ‚Äì Present\\n\\n Suggest Position\\n\\n#### Advisors, Relations & Conflicts\\n\\nNo relations added\\n\\n Suggest Relation\\n\\n#### Expertise [...] equivariant neural network, domain adaptation, domain generalization, molecular, physics, contrastive learning, symmetry, crystal, phase transition\\n\\nPresent\\n\\n Suggest Expertise', 'score': 0.7154444, 'raw_content': None}, {'url': 'https://www.aminer.cn/profile/renjun-xu/53f42ceddabfaedd74d30355?source=bz1', 'title': 'Renjun Xu - Center for Data Science, Zhejiang University', 'content': 'Renjun Xu - Center for Data Science, Zhejiang University | ‰∫∫ÊâçÁîªÂÉè - AMiner\\n\\n\\n\\nResearch\\n\\nCenter for Data Science Zhejiang University\\n\\n„ÄÅ„ÄäInternational Joint Conference on Artificial Intelligence„Äã(IJCAI, CCF-A), „ÄäIEEE Transactions on Knowledge and Data Engineering„Äã(TKDE, CCF-A)‰∫§ÂèâÈ¢ÜÂüüÂèëË°®Â§öÁØáÂõΩÈôÖÈ°∂Â∞ñÊúüÂàäÂíå‰ºöËÆÆÊñáÁ´†ÔºåCVPR„ÄÅAAAI„ÄÅNIPS„ÄÅTPAMI„ÄÅTIP„ÄÅTLTÁ≠âÈ°∂Á∫ß‰∫∫Â∑•Êô∫ËÉΩÊúüÂàäÂíå‰ºöËÆÆÁ®ãÂ∫èÂßîÂëò‰ºöÂßîÂëòÔºåËç£Ëé∑2020Âπ¥Â∫¶‰∏ñÁïå‰∫∫Â∑•Êô∫ËÉΩÂ§ß‰ºöÈùíÂπ¥‰ºòÁßÄËÆ∫ÊñáÊèêÂêçÂ•ñÔºåÊåáÂØºÂπ∂Êé®ËçêÁöÑÊâÄÊúâÂ≠¶ÁîüÂùáÂ∑≤ÊãøÂà∞È∫ªÁúÅÁêÜÂ∑•Â≠¶Èô¢(MIT)„ÄÅÂç°ÂÜÖÂü∫Ê¢ÖÈöÜÂ§ßÂ≠¶(CMU)Á≠âÂÖ®ÁêÉÈ°∂Â∞ñÂêçÊ†°ÁöÑofferÔºÅ\\n\\nEducation\\n\\nSign in to view more\\n\\nExperience\\n\\nSign in to view more [...] The page data are from open Internet sources, cooperative publishers and automatic analysis results through AI technology. We do not make any commitments and guarantees for the validity, accuracy, correctness, reliability, completeness and timeliness of the page data. If you have any questions, please contact us by email: report@aminer.cn\\n\\nSwipe to Fine Result [...] Research Interests\\n\\n2012 2025\\n\\nPapers ÂÖ± 39 ÁØá Patents ÂÖ± 9 ÁØá Author Statistics Co-Author Similar Experts\\n\\nBy Year By Citation ‰∏ªÈ¢òÁ≠õÈÄâ ÊúüÂàäÁ∫ßÂà´Á≠õÈÄâ Âêà‰ΩúËÄÖÁ≠õÈÄâ Âêà‰ΩúÊú∫ÊûÑÁ≠õÈÄâ\\n\\nÊó∂Èó¥\\n\\nÂºïÁî®Èáè\\n\\n‰∏ªÈ¢ò\\n\\nÊúüÂàäÁ∫ßÂà´\\n\\nÂêà‰ΩúËÄÖ\\n\\nÂêà‰ΩúÊú∫ÊûÑ\\n\\nAll 2025 2024 2023 2022 2021 2020 2015 2014 2013 2012 2010 2006\\n\\nDo PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning Vs. Memorization in Large Language Models\\n\\nYang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan\\n\\narXiv ¬∑ Computation and LanguageÔºà2025Ôºâ\\n\\nCited 0 Views 11 Bibtex\\n\\n0\\n\\n11', 'score': 0.6030211, 'raw_content': None}, {'url': 'https://hurenjun.github.io/', 'title': \"Renjun Hu's Homepage\", 'content': \"various business domains including feed recommendation, user growth, online marketing, and LLM-as-a-Judge. Since January 2025, he has joined the School of Data Science and Engineering, East China Normal University as a young researcher. His recent research interests include robust machine learning and the understanding, evaluation, and applications of large language models. [...] Renjun Hu received his Bachelor's degree in 2014 and Ph.D. in 2020 from the School of Computer Science and Engineering at Beihang University. From September 2017 to April 2018, he was a joint Ph.D. student in the Data Mining Group at Rutgers University. He then worked as a research intern at the Business Intelligence Lab of Baidu Research from May 2018 to September 2019. During 2020 to 2024, he served as an algorithm engineer at Alibaba Cloud, contributing to AI-driven transformations across [...] Young Researcher, East China Normal University, January 2025 - present\\n Algorithm engineer, Alibaba Group, July 2020 - January 2025\\n Research intern, Baidu Business Intelligence Lab, May 2018 - September 2019\\n Visiting student, Rutgers University, September 2017 - April 2018\", 'score': 0.5760895, 'raw_content': None}, {'url': 'https://smtown-nctzens.fandom.com/wiki/RENJUN/Facts', 'title': 'RENJUN/Facts - NCT Wiki - Fandom', 'content': \"He has a birthmark on the back of his hand\\n He used to have a snaggletooth back in 2016\\n He had/has lingual braces\\n He is one of the shortest members of NCT\\n He has a small dimple\\n\\n## Nicknames[]\\n\\n Golden Hands\\n Injeolmi\\n Injun (In-Joon)\\n JunJun\\n King of Losing\\n Moomin Otaku\\n Paper Doll/Man\\n Pure Boy\\n Shoulder Gangster\\n The One Who Brightens The World\\n The Prince of China\\n\\n## Relationships[] [...] Passed an online audition to SM Entertainment and got called the day before the actual audition date and so he talked to his parents and took a 3-hour train ride the next morning for the auditions and passed. RENJUN was accepted because of his dancing skills but after training, he became one of the main vocalists of NCT.\\n\\n## Personality[]\\n\\n## Appearance[] [...] RENJUN was a trainee for 1 year.\\n  + He was accepted to SM Entertainment through the 2015 Shenyang SM Global Audition, China in July.\\n  + RENJUN joined in 2015 and debuted in 2016.\\n He was announced as a NCT member in August 2016.\\n When watching the reality show, K-pop Star, RENJUN was indecisive on which company to audition to between SM, YG, and JYP. However, once he saw EXO, he decided to audition for SM's Global Audition when he was 15 years old.\\n\\n#### Casting story[]\", 'score': 0.49260366, 'raw_content': None}, {'url': 'https://www.linkedin.com/pub/dir/Renjun/Xu', 'title': '40+ \"Renjun Xu\" profiles', 'content': 'Sign Up | LinkedIn \\n\\nAgree & Join LinkedIn\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n\\nSkip to main contentLinkedIn\\n\\nJoin LinkedIn\\n\\nImage 1: Profile photo Not you? \\n\\n Remove photo \\n\\nFirst name \\n\\nLast name \\n\\nEmail \\n\\nPassword (6+ characters) \\n\\nBy clicking Agree & Join, you agree to the LinkedIn User Agreement, Privacy Policy, and Cookie Policy.\\n\\n Agree & Join \\n\\nor\\n\\nAlready on Linkedin?  Sign in\\n\\nSecurity verification [...] Sign in\\n\\n Email or phone  \\n\\n Password  \\n\\nShow\\n\\nForgot password? Sign in \\n\\nor\\n\\nBy clicking Continue to join or sign in, you agree to LinkedIn‚Äôs User Agreement, Privacy Policy, and Cookie Policy.\\n\\nNew to Linkedin?  Join now [...] ‡§π‡§ø‡§Ç‡§¶‡•Ä (Hindi) \\n        Magyar (Hungarian) \\n        Bahasa Indonesia (Indonesian) \\n        Italiano (Italian) \\n        ◊¢◊ë◊®◊ô◊™ (Hebrew) \\n        Êó•Êú¨Ë™û (Japanese) \\n        ÌïúÍµ≠Ïñ¥ (Korean) \\n        ‡§Æ‡§∞‡§æ‡§†‡•Ä (Marathi) \\n        Bahasa Malaysia (Malay) \\n        Nederlands (Dutch) \\n        Norsk (Norwegian) \\n        ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä (Punjabi) \\n        Polski (Polish) \\n        Portugu√™s (Portuguese) \\n        Rom√¢nƒÉ (Romanian) \\n        –†—É—Å—Å–∫–∏–π (Russian) \\n        Svenska (Swedish) \\n        ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å (Telugu)', 'score': 0.48879638, 'raw_content': None}], 'response_time': 1.66, 'request_id': 'b2176214-dbe4-429d-bc3a-047e48ce42c1'}), ToolMessage(content='[{\"title\": \"Jingwen Peng Email & Phone Number | Manulife Lead ...\", \"url\": \"https://rocketreach.co/jingwen-peng-email_28909123\", \"content\": \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\\\n   2010 - 2012 Research Analyst @ Congress Asset Management\\\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\\\n   2007 - 2007 Intern Analyst @ Bank of China\\\\n\\\\n see less  \\\\n\\\\n### Jingwen Peng Education\\\\n\\\\n   Boston University Questrom School of Business \\\\nMaster of Arts ( Mathematical Finance)\\\\n\\\\n2008 - 2009\\\\n   Peking University \\\\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\\\n\\\\n2004 - 2008\\\\n\\\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng\\'s profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\\\n\\\\n2\\\\n       hotmail.com\\\\n       libertymutualgroup.com\\\\n\\\\n   \\\\nImage 8: Bpifrance Assurance Export Employee Jingwen Peng\\'s profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\\\n\\\\n1\\\\n       bpifrance.fr\\\\n\\\\nView Similar Profiles\\\\n\\\\nTop Manulife Employees\", \"score\": 0.91156644}, {\"title\": \"US-China veterinary program at K-State celebrates ...\", \"url\": \"https://www.k-state.edu/media/newsreleases/2024-06/US-China-joint-veterinary-program-at-KState-celebrates-graduating-class-and-homecoming-event.html\", \"content\": \"of Missouri.At the homecoming event, recent graduates, current students and friends presented about their experiences in veterinary college. One student\\'s experiences included a close brush with a Kansas weather phenomenon.\\\\\"In my fourth year, I learned that I love dental procedures,\\\\\" said Jingwen Peng, a K-State Doctor of Veterinary Medicine graduate. \\\\\"While on the equine field service, I did dental [exams] on horses, mules and donkeys. Also while on equine field service, I got a bonus view of [...] ###### The recent graduates of the U.S.-China Joint Doctor of Veterinary Medicine Program received purple stethoscopes after giving presentations about their educational experiences. From left: Lei Wang, program manager for the U.S.-China Center for Animal Health, graduates Yuanjue Tan, Xingy Tang, Xiang Yu, Cong Zhu, Jingwen Peng and Hodes Family Dean Bonnie Rush. | Download this photo. [...] \\\\\"Great challenges lie in front of us, but that also comes with great possibilities. I think we have learned from the best, and now is the best time to go back to our country to witness and, more importantly, be part of the growing and developing of veterinary medicine in China.\\\\\"In addition to Peng and Tang, the May 2024 Doctor of Veterinary Medicine graduates are Xiangyu Lin from Kansas State University and Dr. Cong Zhu from the University of Minnesota. The Chinese graduates of the program will\", \"score\": 0.6972179}, {\"title\": \"Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn\", \"url\": \"https://www.linkedin.com/in/jpeng19#:~:text=Devised creative short videos content,and refined data-driven strategies.&text=Grew social media presence through,Instagram, FB, and YouTube.\", \"content\": \"‚óè\\\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\\\n\\\\n‚óè\\\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\\\n\\\\n‚óè\\\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\\\n### Marketing Analyst  \\\\nEmpire City Casino  \\\\nMay 2025 - Present   \\\\nYonkers, New York, United States  \\\\n\\\\n### Amazon  \\\\nAmazon  \\\\nN/A - Present   \\\\nBeijing, China  \\\\n\\\\n### Marketing Analyst  \\\\nJiyuzhoutian Information Technology  \\\\nApr 2019 - Sep 2019   \\\\nBeijing, China  \\\\n‚óè\\\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.\", \"score\": 0.6301622}, {\"title\": \"Jingwen Peng - U of Rochester Simon STEM MSBA\", \"url\": \"https://www.linkedin.com/in/jpeng19\", \"content\": \"‚óè\\\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\\\n\\\\n‚óè\\\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\\\n\\\\n‚óè\\\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] - I\\'m excited to share that our consulting project with the Rochester Fire Department has been a resounding success! üéâ As part of a fantastic team‚Ä¶  \\\\nLiked by Jingwen Peng  \\\\nView Post  \\\\nActivity Image\\\\n\\\\n- I\\'m thrilled to announce the completion of my first consulting project as Project Manager with Simon Vision Consulting! Working alongside my‚Ä¶  \\\\nLiked by Jingwen Peng  \\\\nView Post  \\\\nActivity Image\", \"score\": 0.6213807}, {\"title\": \"The complete mitochondrial genome and phylogenetic ...\", \"url\": \"https://pmc.ncbi.nlm.nih.gov/articles/PMC9225737/\", \"content\": \"1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\\\n\\\\nFind articles by Jingwen Peng\\\\n\\\\n1, Kexing Cheng\\\\n\\\\n### Kexing Cheng\\\\n\\\\n1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\\\n\\\\nFind articles by Kexing Cheng\\\\n\\\\n1, Jiahui Guo\\\\n\\\\n### Jiahui Guo\\\\n\\\\n1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\\\n\\\\nFind articles by Jiahui Guo\\\\n\\\\n1, Zhiao Pei\\\\n\\\\n### Zhiao Pei [...] :1018‚Äì1020. doi: 10.1080/23802359.2022.2080598\\\\n\\\\n   Search in PMC\\\\n   Search in PubMed\\\\n   View in NLM Catalog\\\\n   Add to search\\\\n\\\\nThe complete mitochondrial genome and phylogenetic analysis of _Illiberis pruni_ Dyar, 1905 (Lepidoptera: Zygaenidae)\\\\n\\\\nYanbin Nan\\\\n\\\\n### Yanbin Nan\\\\n\\\\n1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\\\n\\\\nFind articles by Yanbin Nan\\\\n\\\\n1,, Jingwen Peng\\\\n\\\\n### Jingwen Peng\", \"score\": 0.53342235}]', name='tavily_search_results_json', id='cc3c88e3-919c-4465-b87b-75946686ba40', tool_call_id='call_tthF5zAGFBjy8VcpobOmGRfV', artifact={'query': 'Jingwen Peng', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://rocketreach.co/jingwen-peng-email_28909123', 'title': 'Jingwen Peng Email & Phone Number | Manulife Lead ...', 'content': \"Jingwen Peng, based in Boston, Massachusetts, United States, is currently a Lead Analyst, Investment Analytics at Manulife Investment Management at Manulife. Jingwen Peng brings experience from previous roles at Manulife Asset Management, Congress Asset Management and Prelude Asset Management. Jingwen Peng holds a 2008 - 2009 Master of Arts in Mathematical Finance @ Boston University Questrom School of Business. With a robust skill set that includes Quantitative Finance, Asset Management, [...] - [x]  see more  \\n   2010 - 2012 Research Analyst @ Congress Asset Management\\n   2009 - 2010 Research Analyst @ Prelude Asset Management\\n   2007 - 2007 Intern Analyst @ Bank of China\\n\\n see less  \\n\\n### Jingwen Peng Education\\n\\n   Boston University Questrom School of Business \\nMaster of Arts ( Mathematical Finance)\\n\\n2008 - 2009\\n   Peking University \\nBachelor of Science ( Mathematics with a concerntration in Financial Mathematics)\\n\\n2004 - 2008\\n\\n### Jingwen Peng Skills [...] Image 7: Liberty Mutual Investments Employee Jingwen Peng's profile photo ### Jingwen Peng #### Director II - Lead Data Steward at Liberty Mutual Investments Boston, MA, US   View \\n\\n2\\n       hotmail.com\\n       libertymutualgroup.com\\n\\n   \\nImage 8: Bpifrance Assurance Export Employee Jingwen Peng's profile photo ### Jingwen Peng #### Product owner at Bpifrance Assurance Export Pontoise, FR   View \\n\\n1\\n       bpifrance.fr\\n\\nView Similar Profiles\\n\\nTop Manulife Employees\", 'score': 0.91156644, 'raw_content': None}, {'url': 'https://www.k-state.edu/media/newsreleases/2024-06/US-China-joint-veterinary-program-at-KState-celebrates-graduating-class-and-homecoming-event.html', 'title': 'US-China veterinary program at K-State celebrates ...', 'content': 'of Missouri.At the homecoming event, recent graduates, current students and friends presented about their experiences in veterinary college. One student\\'s experiences included a close brush with a Kansas weather phenomenon.\"In my fourth year, I learned that I love dental procedures,\" said Jingwen Peng, a K-State Doctor of Veterinary Medicine graduate. \"While on the equine field service, I did dental [exams] on horses, mules and donkeys. Also while on equine field service, I got a bonus view of [...] ###### The recent graduates of the U.S.-China Joint Doctor of Veterinary Medicine Program received purple stethoscopes after giving presentations about their educational experiences. From left: Lei Wang, program manager for the U.S.-China Center for Animal Health, graduates Yuanjue Tan, Xingy Tang, Xiang Yu, Cong Zhu, Jingwen Peng and Hodes Family Dean Bonnie Rush. | Download this photo. [...] \"Great challenges lie in front of us, but that also comes with great possibilities. I think we have learned from the best, and now is the best time to go back to our country to witness and, more importantly, be part of the growing and developing of veterinary medicine in China.\"In addition to Peng and Tang, the May 2024 Doctor of Veterinary Medicine graduates are Xiangyu Lin from Kansas State University and Dr. Cong Zhu from the University of Minnesota. The Chinese graduates of the program will', 'score': 0.6972179, 'raw_content': None}, {'url': 'https://www.linkedin.com/in/jpeng19#:~:text=Devised creative short videos content,and refined data-driven strategies.&text=Grew social media presence through,Instagram, FB, and YouTube.', 'title': 'Jingwen Peng - U of Rochester Simon STEM MSBA - LinkedIn', 'content': '‚óè\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\n\\n‚óè\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\n\\n‚óè\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] ## Experience\\n### Marketing Analyst  \\nEmpire City Casino  \\nMay 2025 - Present   \\nYonkers, New York, United States  \\n\\n### Amazon  \\nAmazon  \\nN/A - Present   \\nBeijing, China  \\n\\n### Marketing Analyst  \\nJiyuzhoutian Information Technology  \\nApr 2019 - Sep 2019   \\nBeijing, China  \\n‚óè\\tSEO for website CouponBirds and ASO for app Spark, improved CTR by 50%, enhancing visibility and user acquisition.', 'score': 0.6301622, 'raw_content': None}, {'url': 'https://www.linkedin.com/in/jpeng19', 'title': 'Jingwen Peng - U of Rochester Simon STEM MSBA', 'content': \"‚óè\\tAuthored product requirement documentation, followed up on new features and optimization based on customer feedback.\\n\\n‚óè\\tDevised creative short videos content, elevated ad CTR by 4 times on Google Ads and refined data-driven strategies.\\n\\n‚óè\\tGrew social media presence through influencer marketing, acquired 1,000+ new users on Instagram, FB, and YouTube. [...] At Amazon, my role as a Site Merchandising analyst was pivotal in enhancing the Kindle E-book business through data-driven strategies<br><br> By automating reports and refining forecasting models, our team significantly improved operational efficiency and influenced strategic decisions that positively impacted the growth of E-book store and Kindle Unlimited<br><br> My technical acumen, particularly in Excel, SQL and Python, was instrumental in automating processes, reducing manual workloads, [...] - I'm excited to share that our consulting project with the Rochester Fire Department has been a resounding success! üéâ As part of a fantastic team‚Ä¶  \\nLiked by Jingwen Peng  \\nView Post  \\nActivity Image\\n\\n- I'm thrilled to announce the completion of my first consulting project as Project Manager with Simon Vision Consulting! Working alongside my‚Ä¶  \\nLiked by Jingwen Peng  \\nView Post  \\nActivity Image\", 'score': 0.6213807, 'raw_content': None}, {'url': 'https://pmc.ncbi.nlm.nih.gov/articles/PMC9225737/', 'title': 'The complete mitochondrial genome and phylogenetic ...', 'content': '1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\n\\nFind articles by Jingwen Peng\\n\\n1, Kexing Cheng\\n\\n### Kexing Cheng\\n\\n1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\n\\nFind articles by Kexing Cheng\\n\\n1, Jiahui Guo\\n\\n### Jiahui Guo\\n\\n1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\n\\nFind articles by Jiahui Guo\\n\\n1, Zhiao Pei\\n\\n### Zhiao Pei [...] :1018‚Äì1020. doi: 10.1080/23802359.2022.2080598\\n\\n   Search in PMC\\n   Search in PubMed\\n   View in NLM Catalog\\n   Add to search\\n\\nThe complete mitochondrial genome and phylogenetic analysis of _Illiberis pruni_ Dyar, 1905 (Lepidoptera: Zygaenidae)\\n\\nYanbin Nan\\n\\n### Yanbin Nan\\n\\n1 College of Agriculture and Animal Husbandry, Qinghai University, Xining, Qinghai, China\\n\\nFind articles by Yanbin Nan\\n\\n1,, Jingwen Peng\\n\\n### Jingwen Peng', 'score': 0.53342235, 'raw_content': None}], 'response_time': 2.55, 'request_id': 'ea1f02f8-ee9c-4759-8dd9-80b0f9633e22'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='I found that Renjun Xu is currently a Principal Researcher at Zhejiang University. \\n\\nJingwen Peng is currently a Lead Analyst in Investment Analytics at Manulife Investment Management. \\n\\nWould you like to know more details or about other authors?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 7769, 'total_tokens': 7819, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 3456}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHApVLUvkso15PSed75M3m8PbCLd', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--741153ec-0593-4731-9a05-fc5ea9a0d047-0', usage_metadata={'input_tokens': 7769, 'output_tokens': 50, 'total_tokens': 7819, 'input_token_details': {'audio': 0, 'cache_read': 3456}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"Search Arxiv for the A Comprehensive Survey of Deep Research paper, then search each of the authors to find out where they work now using Tavily!\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        #if node == \"action\":\n",
        "          #print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXzDlZVz1Hnf"
      },
      "source": [
        "#### üèóÔ∏è Activity #2:\n",
        "\n",
        "Please write out the steps the agent took to arrive at the correct answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ‚úÖ Answer:\n",
        " Our state object was populated with our request\n",
        "2. The state object was passed into our entry point (agent node) and the agent node.\n",
        "The agent used the LLM model and determined it needs to call both tools. It adds call to arxiv with the name of the paper and call to tavily_search_results_json with 'author of' the name of the paper.\n",
        "3. The flow passes to conditional node which determines actions as described above need to be taken and calls the tools\n",
        "4. Each tool is executed and the results are appended to the state object and returned to the agent\n",
        "5. agent executest the LLM to parse the results and determine the next course of action\n",
        "6. LLM parses out the two author names and adds two calls to the state object. Each call per author to tavily_search_results_json\n",
        "7. the flow passes to the conditional which determines actions as described above need to be taken and calls the tavily_search_results_json twice\n",
        "6. the two calls are executed and the results are appended to the state and returned to the agent.\n",
        "7. Agent LLM decides to add no further action to the state since it has the required information and the conditional node returns a call to end the flow.\n",
        "\n",
        "Hindsight: More prompt tuning maybe needed \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_qBkJDzDtUv6qdarrdfqAPLyw', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'arxiv'}, 'type': 'function'}, {'id': 'call_YTYsVBlQDsvF08Bftoj8dOX2', 'function': {'arguments': '{\"query\": \"A Comprehensive Survey of Deep Research\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 241, 'total_tokens': 299, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHArW9icN9korf6PAJlsVCT6Sb6G', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--afdc0bae-2b77-430b-aebb-fc624fba288e-0', tool_calls=[{'name': 'arxiv', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_qBkJDzDtUv6qdarrdfqAPLyw', 'type': 'tool_call'}, {'name': 'tavily_search_results_json', 'args': {'query': 'A Comprehensive Survey of Deep Research'}, 'id': 'call_YTYsVBlQDsvF08Bftoj8dOX2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 241, 'output_tokens': 58, 'total_tokens': 299, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='Published: 2025-06-14\\nTitle: A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\nAuthors: Renjun Xu, Jingwen Peng\\nSummary: This survey examines the rapidly evolving field of Deep Research systems --\\nAI-powered applications that automate complex research workflows through the\\nintegration of large language models, advanced information retrieval, and\\nautonomous reasoning capabilities. We analyze more than 80 commercial and\\nnon-commercial implementations that have emerged since 2023, including\\nOpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and\\nnumerous open-source alternatives. Through comprehensive examination, we\\npropose a novel hierarchical taxonomy that categorizes systems according to\\nfour fundamental technical dimensions: foundation models and reasoning engines,\\ntool utilization and environmental interaction, task planning and execution\\ncontrol, and knowledge synthesis and output generation. We explore the\\narchitectural patterns, implementation approaches, and domain-specific\\nadaptations that characterize these systems across academic, scientific,\\nbusiness, and educational applications. Our analysis reveals both the\\nsignificant capabilities of current implementations and the technical and\\nethical challenges they present regarding information accuracy, privacy,\\nintellectual property, and accessibility. The survey concludes by identifying\\npromising research directions in advanced reasoning architectures, multimodal\\nintegration, domain specialization, human-AI collaboration, and ecosystem\\nstandardization that will likely shape the future evolution of this\\ntransformative technology. By providing a comprehensive framework for\\nunderstanding Deep Research systems, this survey contributes to both the\\ntheoretical understanding of AI-augmented knowledge work and the practical\\ndevelopment of more capable, responsible, and accessible research technologies.\\nThe paper resources can be viewed at\\nhttps://github.com/scienceaix/deepresearch.\\n\\nPublished: 2021-03-05\\nTitle: A comprehensive survey on point cloud registration\\nAuthors: Xiaoshui Huang, Guofeng Mei, Jian Zhang, Rana Abbas\\nSummary: Registration is a transformation estimation problem between two point clouds,\\nwhich has a unique and critical role in numerous computer vision applications.\\nThe developments of optimization-based methods and deep learning methods have\\nimproved registration robustness and efficiency. Recently, the combinations of\\noptimization-based and deep learning methods have further improved performance.\\nHowever, the connections between optimization-based and deep learning methods\\nare still unclear. Moreover, with the recent development of 3D sensors and 3D\\nreconstruction techniques, a new research direction emerges to align\\ncross-source point clouds. This survey conducts a comprehensive survey,\\nincluding both same-source and cross-source registration methods, and summarize\\nthe connections between optimization-based and deep learning methods, to\\nprovide further research insight. This survey also builds a new benchmark to\\nevaluate the state-of-the-art registration algorithms in solving cross-source\\nchallenges. Besides, this survey summarizes the benchmark data sets and\\ndiscusses point cloud registration applications across various domains.\\nFinally, this survey proposes potential research directions in this rapidly\\ngrowing field.\\n\\nPublished: 2023-07-07\\nTitle: A Survey of Deep Learning in Sports Applications: Perception, Comprehension, and Decision\\nAuthors: Zhonghan Zhao, Wenhao Chai, Shengyu Hao, Wenhao Hu, Guanhong Wang, Shidong Cao, Mingli Song, Jenq-Neng Hwang, Gaoang Wang\\nSummary: Deep learning has the potential to revolutionize sports performance, with\\napplications ranging from perception and comprehension to decision. This paper\\npresents a comprehensive survey of deep learning in sports performance,\\nfocusing on three main aspects: algorithms, datasets and virtual environments,\\nand challenges. Firstly, we discuss th', name='arxiv', id='3b0ad70f-f4a2-4f3b-bda1-b19cdd81b183', tool_call_id='call_qBkJDzDtUv6qdarrdfqAPLyw'), ToolMessage(content='[{\"title\": \"[2506.12594] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/abs/2506.12594\", \"content\": \"> Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\\\n\\\\n> cs > arXiv:2506.12594\\\\n\\\\n# Computer Science > Artificial Intelligence\\\\n\\\\narXiv:2506.12594 (cs)\\\\n\\\\n[Submitted on 14 Jun 2025]\\\\n\\\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\\\n\\\\nAuthors:Renjun Xu, Jingwen Peng [...] |  |  |\\\\n --- |\\\\n| Comments: | 95 pages, 11 figures |\\\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\\\n| ACM classes: | I.2.8 |\\\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\\\n|  |  arXiv-issued DOI via DataCite |\\\\n\\\\n## Submission history\\\\n\\\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\\\n\\\\nFull-text links:\\\\n\\\\n## Access Paper:\", \"score\": 0.8921218}, {\"title\": \"A Comprehensive Survey of Deep Research: Systems ... - alphaXiv\", \"url\": \"https://www.alphaxiv.org/overview/2506.12594\", \"content\": \"This comprehensive survey by Renjun Xu and Jingwen Peng from Zhejiang University addresses the rapidly emerging field of Deep Research systems‚ÄîAI-powered applications that integrate large language models, advanced information retrieval, and autonomous reasoning to automate complex research workflows. The paper establishes the first systematic framework for understanding this domain, which has evolved dramatically since 2023, encompassing over 80 commercial and open-source implementations. [...] This survey establishes Deep Research as a transformative paradigm that extends beyond task automation to fundamental research methodology transformation. By providing the first comprehensive framework for understanding and developing these systems, the work contributes both theoretical foundations and practical guidance for researchers, developers, and practitioners. [...] ## Performance Evaluation and Benchmarking\\\\n\\\\nThe survey establishes a comprehensive evaluation framework addressing the multifaceted nature of Deep Research systems. Traditional AI benchmarks like MMLU, HLE, HotpotQA, and GAIA provide baseline performance metrics, while emerging specialized benchmarks (AAAR-1.0, DSBench, SciCode) address research-specific capabilities.\", \"score\": 0.8872928}, {\"title\": \"[PDF] A Comprehensive Survey of Deep Research - arXiv\", \"url\": \"https://arxiv.org/pdf/2506.12594?\", \"content\": \"Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches [...] ‚àô Differentiating from Pure LLM Applications: Applications that simply wrap LLMs with research-oriented prompts lack the environmental interaction, tool integration, and workflow automation capabilities that characterize true Deep Research systems. This survey specifically examines systems that exhibit at least two of the three core dimensions, with a focus on those incorporating large language models as their foundational reasoning engine. Our scope encompasses commercial offerings such as\", \"score\": 0.8783249}, {\"title\": \"Deep Research Tools: A Comprehensive Guide and Comparison\", \"url\": \"https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122\", \"content\": \"making it great when you need information quickly without waiting around. [...] overview. [...] content, it might miss non-scholarly but relevant information (news, statistics from reports, etc.).\", \"score\": 0.5030035}, {\"title\": \"The Rise of Deep Research - AlphaSense\", \"url\": \"https://www.alpha-sense.com/resources/research-articles/deep-research-tools-2025/\", \"content\": \"Perplexity prioritizes speed, returning results in under three minutes.\\\\n xAI\\'s and You.com\\'s deep research tools balance speed and depth, delivering responses in approximately five minutes.\\\\n Google Gemini‚Äôs Deep Research is slightly slower, typically generating outputs in under 10 minutes.\\\\n OpenAI‚Äôs and AlphaSense‚Äôs deep research tools offer very comprehensive responses but users may need to wait up to 30 minutes for them to complete. [...] Google, OpenAI, and xAI use proprietary large language models to generate comprehensive reports.\\\\n Perplexity takes a different approach, using a customized version of the open-source DeepSeek R1 model.\\\\n Microsoft‚Äôs Researcher ‚Äúcombines OpenAI‚Äôs deep research model with Microsoft 365 Copilot‚Äôs advanced orchestration and deep search capabilities.‚Äù [...] Whether you‚Äôre a corporate strategist, investment banking analyst, academic, or simply a curious mind, embracing these innovations means tapping into a more connected, insightful, and efficient approach to generating knowledge and making decisions.\\\\n\\\\nDeep research tools mark the beginning of a more intelligent and integrated future for knowledge discovery.\\\\n\\\\nRead the full report for a deeper dive into deep research tools shaping 2025.\", \"score\": 0.38901308}]', name='tavily_search_results_json', id='fb613e7f-cbec-4b57-888f-768042b0955a', tool_call_id='call_YTYsVBlQDsvF08Bftoj8dOX2', artifact={'query': 'A Comprehensive Survey of Deep Research', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://arxiv.org/abs/2506.12594', 'title': '[2506.12594] A Comprehensive Survey of Deep Research - arXiv', 'content': '> Abstract:This survey examines the rapidly evolving field of Deep Research systems -- AI-powered applications that automate complex research workflows through the integration of large language models, advanced information retrieval, and autonomous reasoning capabilities. We analyze more than 80 commercial and non-commercial implementations that have emerged since 2023, including OpenAI/Deep Research, Gemini/Deep Research, Perplexity/Deep Research, and numerous open-source alternatives. Through [...] We gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\\n\\n> cs > arXiv:2506.12594\\n\\n# Computer Science > Artificial Intelligence\\n\\narXiv:2506.12594 (cs)\\n\\n[Submitted on 14 Jun 2025]\\n\\n# Title:A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications\\n\\nAuthors:Renjun Xu, Jingwen Peng [...] |  |  |\\n --- |\\n| Comments: | 95 pages, 11 figures |\\n| Subjects: | Artificial Intelligence (cs.AI); Multiagent Systems (cs.MA) |\\n| ACM classes: | I.2.8 |\\n| Cite as: | arXiv:2506.12594 [cs.AI] |\\n|  | (or  arXiv:2506.12594v1 [cs.AI] for this version) |\\n|  |  arXiv-issued DOI via DataCite |\\n\\n## Submission history\\n\\nFrom: Renjun Xu [view email] [v1] Sat, 14 Jun 2025 18:19:05 UTC (652 KB)\\n\\nFull-text links:\\n\\n## Access Paper:', 'score': 0.8921218, 'raw_content': None}, {'url': 'https://www.alphaxiv.org/overview/2506.12594', 'title': 'A Comprehensive Survey of Deep Research: Systems ... - alphaXiv', 'content': 'This comprehensive survey by Renjun Xu and Jingwen Peng from Zhejiang University addresses the rapidly emerging field of Deep Research systems‚ÄîAI-powered applications that integrate large language models, advanced information retrieval, and autonomous reasoning to automate complex research workflows. The paper establishes the first systematic framework for understanding this domain, which has evolved dramatically since 2023, encompassing over 80 commercial and open-source implementations. [...] This survey establishes Deep Research as a transformative paradigm that extends beyond task automation to fundamental research methodology transformation. By providing the first comprehensive framework for understanding and developing these systems, the work contributes both theoretical foundations and practical guidance for researchers, developers, and practitioners. [...] ## Performance Evaluation and Benchmarking\\n\\nThe survey establishes a comprehensive evaluation framework addressing the multifaceted nature of Deep Research systems. Traditional AI benchmarks like MMLU, HLE, HotpotQA, and GAIA provide baseline performance metrics, while emerging specialized benchmarks (AAAR-1.0, DSBench, SciCode) address research-specific capabilities.', 'score': 0.8872928, 'raw_content': None}, {'url': 'https://arxiv.org/pdf/2506.12594?', 'title': '[PDF] A Comprehensive Survey of Deep Research - arXiv', 'content': 'Deep Research refers to the systematic application of AI technologies to automate and enhance research processes through three core dimensions: (1) Intelligent Knowledge Discovery: Automating literature search, hypothesis generation, and pattern recognition across heterogeneous data sources (2) End-to-End Workflow Automation: Integrating experimental design, data collection, analysis, and result interpretation into unified AI-driven pipelines (3) Collaborative Intelligence Enhancement: [...] This survey addresses three fundamental questions: (1) How do architectural choices (system architecture, implementation approach, functional capabilities) impact Deep Research effectiveness? (2) What technical innovations have emerged in LLM fine-tuning, retrieval mechanisms, and workflow orchestration across the spectrum of Deep Research implementations? (3) How do existing systems balance performance, usability, and ethical considerations, and what patterns emerge from comparing approaches [...] ‚àô Differentiating from Pure LLM Applications: Applications that simply wrap LLMs with research-oriented prompts lack the environmental interaction, tool integration, and workflow automation capabilities that characterize true Deep Research systems. This survey specifically examines systems that exhibit at least two of the three core dimensions, with a focus on those incorporating large language models as their foundational reasoning engine. Our scope encompasses commercial offerings such as', 'score': 0.8783249, 'raw_content': None}, {'url': 'https://bytebridge.medium.com/deep-research-tools-a-comprehensive-guide-and-comparison-a38077d52122', 'title': 'Deep Research Tools: A Comprehensive Guide and Comparison', 'content': 'making it great when you need information quickly without waiting around. [...] overview. [...] content, it might miss non-scholarly but relevant information (news, statistics from reports, etc.).', 'score': 0.5030035, 'raw_content': None}, {'url': 'https://www.alpha-sense.com/resources/research-articles/deep-research-tools-2025/', 'title': 'The Rise of Deep Research - AlphaSense', 'content': \"Perplexity prioritizes speed, returning results in under three minutes.\\n xAI's and You.com's deep research tools balance speed and depth, delivering responses in approximately five minutes.\\n Google Gemini‚Äôs Deep Research is slightly slower, typically generating outputs in under 10 minutes.\\n OpenAI‚Äôs and AlphaSense‚Äôs deep research tools offer very comprehensive responses but users may need to wait up to 30 minutes for them to complete. [...] Google, OpenAI, and xAI use proprietary large language models to generate comprehensive reports.\\n Perplexity takes a different approach, using a customized version of the open-source DeepSeek R1 model.\\n Microsoft‚Äôs Researcher ‚Äúcombines OpenAI‚Äôs deep research model with Microsoft 365 Copilot‚Äôs advanced orchestration and deep search capabilities.‚Äù [...] Whether you‚Äôre a corporate strategist, investment banking analyst, academic, or simply a curious mind, embracing these innovations means tapping into a more connected, insightful, and efficient approach to generating knowledge and making decisions.\\n\\nDeep research tools mark the beginning of a more intelligent and integrated future for knowledge discovery.\\n\\nRead the full report for a deeper dive into deep research tools shaping 2025.\", 'score': 0.38901308, 'raw_content': None}], 'response_time': 1.96, 'request_id': '97190bab-ac08-4e3f-855f-fe590f1cc328'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='The authors of the paper \"A Comprehensive Survey of Deep Research\" are Renjun Xu and Jingwen Peng. \\n\\nNext, I will search to find out where they currently work.', additional_kwargs={'tool_calls': [{'id': 'call_6ANYTqNe6GvKIpgqgZUc3d7A', 'function': {'arguments': '{\"query\":\"Renjun Xu Jingwen Peng\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 2434, 'total_tokens': 2494, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHAv0FfbvUyd6UGCKPm5BhRFwE6i', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--87b24766-c4aa-4613-8c09-4331636cbdd6-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Renjun Xu Jingwen Peng'}, 'id': 'call_6ANYTqNe6GvKIpgqgZUc3d7A', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2434, 'output_tokens': 60, 'total_tokens': 2494, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"a-comprehensive-survey-of-deep-research-systems-methodologies ...\", \"url\": \"https://warwick.ac.uk/fac/cross_fac/eduport/edufund/projects/yang/projects/a-comprehensive-survey-of-deep-research-systems-methodologies-and-applications/\", \"content\": \"### Project Team\\\\n\\\\n#### Renjun Xu\\\\n\\\\nResearcher\\\\n\\\\n#### Jingwen Peng\\\\n\\\\nResearcher\\\\n\\\\n### Contact Information\\\\n\\\\nFor information about the paper, please contact the authors.\\\\n\\\\nAuthors: Renjun Xu, Jingwen Peng\\\\n\\\\nSource Publication: View Original PaperLink opens in a new window\\\\n\\\\nProject Contact: Dr. Jianhua Yang\\\\n\\\\nLLM Model Version: gpt-4o-mini-2024-07-18\\\\n\\\\nAnalysis Provider: Openai\\\\n\\\\n‚Üê Back to Projects\", \"score\": 0.7065353}, {\"title\": \"[PDF] Reinforced Distillation of Large Language Model Agents - arXiv\", \"url\": \"https://www.arxiv.org/pdf/2509.14257\", \"content\": \"Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model based agents: A survey. Science China Information Sciences, 68(2):121101, 2025.\\\\n12 Preprint Renjun Xu and Jingwen Peng. A comprehensive survey of deep research: Systems, methodologies, and applications. arXiv preprint arXiv:2506.12594, 2025. [...] et al., 2017) have been adapted for natural-language decision-making, where inter-mediate thoughts and tool calls form part of the state (Li et al., 2025a). In tool-augmented settings, recent work optimized multi-tool coordination under real-time constraints (Qian et al., 2025; Xu & Peng, 2025). Despite these advances, challenges remain: long-context rollouts cause instabil-9 Preprint ity (Schulman et al., 2017; Peng et al., 2019), and sparse or delayed rewards hinder credit assign-ment [...] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models.\\\\narXiv e-prints, pp. arXiv‚Äì2407, 2024.\\\\nBofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li, Chenghao Ma, Liang Chen, Runxin Xu, et al. Omni-math: A universal olympiad level mathematic benchmark for large language models. arXiv preprint arXiv:2410.07985, 2024.\", \"score\": 0.7045877}, {\"title\": \"MedResearcher-R1: Expert-Level Medical Deep Researcher via A ...\", \"url\": \"https://arxiv.org/html/2508.14880v2\", \"content\": \"Renjun Xu and Jingwen Peng.\\\\n  A comprehensive survey of deep research: Systems, methodologies, and applications.\\\\n  arXiv preprint arXiv:2506.12594, 2025.\\\\n Yao et al. [2023a]\\\\n\\\\n  Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\\\\n  React: Synergizing reasoning and acting in language models.\\\\n  In International Conference on Learning Representations (ICLR), 2023a.\\\\n Yao et al. [2023b] [...] Xi Wang, Taketomo Isazawa, Liana Mikaelyan, and James Hensman.\\\\n  Kblam: Knowledge base augmented language model, 2025.\\\\n  URL .\\\\n Wang et al. \\\\n\\\\n  Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, et al.\\\\n  Openhands: An open platform for ai software developers as generalist agents.\\\\n  arXiv preprint arXiv:2407.16741, 2024.\\\\n Xu \\\\n\\\\n  Ming Xu.\\\\n  Medicalgpt: Training medical gpt model.\\\\n  , 2023.\\\\n Xu and Peng [...] Jujie He, Jiacai Liu, Chris Yuhao Liu, Rui Yan, Chaojie Wang, Peng Cheng, Xiaoyu Zhang, Fuxiang Zhang, Jiacheng Xu, Wei Shen, et al.\\\\n  Skywork open reasoner 1 technical report.\\\\n  arXiv preprint arXiv:2505.22312, 2025.\\\\n Jiang et al. \\\\n\\\\n  Pengcheng Jiang, Xueqiang Xu, Jiacheng Lin, Jinfeng Xiao, Zifeng Wang, Jimeng Sun, and Jiawei Han.\\\\n  s3: You don‚Äôt need that much data to train a search agent via rl.\\\\n  arXiv preprint arXiv:2505.14146, 2025.\\\\n Jimenez et al.\", \"score\": 0.5573882}, {\"title\": \"Characterizing Deep Research: A Benchmark and Formal ...\", \"url\": \"https://arxiv.org/html/2508.04183v1\", \"content\": \"Evaluating Deep Research. Given that typical DR output involves a detailed report, most evaluation efforts focus on the quality of long-form text output(Du et al., 2025; Xu and Peng, 2025; Chandrahasan et al., 2025). DeepResearch Bench (Du et al., 2025) evaluates deep research by assessing the quality of the final report on aspects such as comprehensiveness, insight, readability, and instruction-following . However, all these metrics are computed by prompting an LLM judge such as GPT-4, which [...] Report issue for preceding element\\\\n\\\\nAlthough there are extensive surveys of deep research(Huang et al., 2025; Xu and Peng, 2025), we find that a formal definition of the problem is lacking. We provide a definition in Section3 that helps characterize the problem.\\\\n\\\\nReport issue for preceding element [...] said information. Rather than the common expectation of a long report-like output, we posit that the defining element of a DR problem is the first sub-task: synthesis of relevant information that could answer a user‚Äôs question, given a document corpus. The information synthesis problem can be conceptualized as a directed acyclic graph (DAG), where the nodes represent information such as original query, retrieved documents and synthesized information while the edges represent actions such as\", \"score\": 0.15575814}, {\"title\": \"Accepted Findings Papers\", \"url\": \"https://2025.aclweb.org/program/find_papers/\", \"content\": \"Revisiting ``The Geometry of Truth‚Äô‚Äô: Emergent Consistent Linear Representation of Truthfulness in Capable Language ModelsYuntai Bao, Tianyu Du, Xuhong Zhang, Xinkui Zhao, Zhengwen Feng, Jianwei Yin\\\\n Comparing Bad Apples to Good Oranges Aligning Large Language Models via Joint Preference OptimizationHritik Bansal, Ashima Suvarna, Gantavya Bhatt, Nanyun Peng, Kai-Wei Chang, Aditya Grover [...] TDCSA: LLM-Guided Top-Down Approach for Robust Citation Sentiment AnalysisFan Gao, Jieyang Peng, Xiaoming Tao, WANG Youzheng\\\\n DeepRTL2: A Versatile Model for RTL-Related TasksYi Liu, Hongji Zhang, Yunhao Zhou, Zhengyuan Shi, Changran XU, Qiang Xu\\\\n The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?Yutao Sun, Mingshuai Chen, Tiancheng Zhao, Ruochen Xu, Zilun Zhang, Jianwei Yin [...] Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-TeachingXiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen M. Meng\\\\n QueryAttack: Jailbreaking Aligned Large Language Models Using Structured Non-natural Query LanguageQingsong Zou, Jingyu Xiao, Qing Li, Zhi Yan, Yuhang Wang, Li Xu, Wenxuan Wang, Kuofeng Gao, Ruoyu Li, Yong Jiang\", \"score\": 0.074157745}]', name='tavily_search_results_json', id='489e3863-85cf-4fa2-8b0e-729c435e8ff7', tool_call_id='call_6ANYTqNe6GvKIpgqgZUc3d7A', artifact={'query': 'Renjun Xu Jingwen Peng', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://warwick.ac.uk/fac/cross_fac/eduport/edufund/projects/yang/projects/a-comprehensive-survey-of-deep-research-systems-methodologies-and-applications/', 'title': 'a-comprehensive-survey-of-deep-research-systems-methodologies ...', 'content': '### Project Team\\n\\n#### Renjun Xu\\n\\nResearcher\\n\\n#### Jingwen Peng\\n\\nResearcher\\n\\n### Contact Information\\n\\nFor information about the paper, please contact the authors.\\n\\nAuthors: Renjun Xu, Jingwen Peng\\n\\nSource Publication: View Original PaperLink opens in a new window\\n\\nProject Contact: Dr. Jianhua Yang\\n\\nLLM Model Version: gpt-4o-mini-2024-07-18\\n\\nAnalysis Provider: Openai\\n\\n‚Üê Back to Projects', 'score': 0.7065353, 'raw_content': None}, {'url': 'https://www.arxiv.org/pdf/2509.14257', 'title': '[PDF] Reinforced Distillation of Large Language Model Agents - arXiv', 'content': 'Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang, Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language model based agents: A survey. Science China Information Sciences, 68(2):121101, 2025.\\n12 Preprint Renjun Xu and Jingwen Peng. A comprehensive survey of deep research: Systems, methodologies, and applications. arXiv preprint arXiv:2506.12594, 2025. [...] et al., 2017) have been adapted for natural-language decision-making, where inter-mediate thoughts and tool calls form part of the state (Li et al., 2025a). In tool-augmented settings, recent work optimized multi-tool coordination under real-time constraints (Qian et al., 2025; Xu & Peng, 2025). Despite these advances, challenges remain: long-context rollouts cause instabil-9 Preprint ity (Schulman et al., 2017; Peng et al., 2019), and sparse or delayed rewards hinder credit assign-ment [...] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models.\\narXiv e-prints, pp. arXiv‚Äì2407, 2024.\\nBofei Gao, Feifan Song, Zhe Yang, Zefan Cai, Yibo Miao, Qingxiu Dong, Lei Li, Chenghao Ma, Liang Chen, Runxin Xu, et al. Omni-math: A universal olympiad level mathematic benchmark for large language models. arXiv preprint arXiv:2410.07985, 2024.', 'score': 0.7045877, 'raw_content': None}, {'url': 'https://arxiv.org/html/2508.14880v2', 'title': 'MedResearcher-R1: Expert-Level Medical Deep Researcher via A ...', 'content': 'Renjun Xu and Jingwen Peng.\\n  A comprehensive survey of deep research: Systems, methodologies, and applications.\\n  arXiv preprint arXiv:2506.12594, 2025.\\n Yao et al. [2023a]\\n\\n  Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\\n  React: Synergizing reasoning and acting in language models.\\n  In International Conference on Learning Representations (ICLR), 2023a.\\n Yao et al. [2023b] [...] Xi Wang, Taketomo Isazawa, Liana Mikaelyan, and James Hensman.\\n  Kblam: Knowledge base augmented language model, 2025.\\n  URL .\\n Wang et al. \\n\\n  Xingyao Wang, Boxuan Li, Yufan Song, Frank F Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, et al.\\n  Openhands: An open platform for ai software developers as generalist agents.\\n  arXiv preprint arXiv:2407.16741, 2024.\\n Xu \\n\\n  Ming Xu.\\n  Medicalgpt: Training medical gpt model.\\n  , 2023.\\n Xu and Peng [...] Jujie He, Jiacai Liu, Chris Yuhao Liu, Rui Yan, Chaojie Wang, Peng Cheng, Xiaoyu Zhang, Fuxiang Zhang, Jiacheng Xu, Wei Shen, et al.\\n  Skywork open reasoner 1 technical report.\\n  arXiv preprint arXiv:2505.22312, 2025.\\n Jiang et al. \\n\\n  Pengcheng Jiang, Xueqiang Xu, Jiacheng Lin, Jinfeng Xiao, Zifeng Wang, Jimeng Sun, and Jiawei Han.\\n  s3: You don‚Äôt need that much data to train a search agent via rl.\\n  arXiv preprint arXiv:2505.14146, 2025.\\n Jimenez et al.', 'score': 0.5573882, 'raw_content': None}, {'url': 'https://arxiv.org/html/2508.04183v1', 'title': 'Characterizing Deep Research: A Benchmark and Formal ...', 'content': 'Evaluating Deep Research. Given that typical DR output involves a detailed report, most evaluation efforts focus on the quality of long-form text output(Du et al., 2025; Xu and Peng, 2025; Chandrahasan et al., 2025). DeepResearch Bench (Du et al., 2025) evaluates deep research by assessing the quality of the final report on aspects such as comprehensiveness, insight, readability, and instruction-following . However, all these metrics are computed by prompting an LLM judge such as GPT-4, which [...] Report issue for preceding element\\n\\nAlthough there are extensive surveys of deep research(Huang et al., 2025; Xu and Peng, 2025), we find that a formal definition of the problem is lacking. We provide a definition in Section3 that helps characterize the problem.\\n\\nReport issue for preceding element [...] said information. Rather than the common expectation of a long report-like output, we posit that the defining element of a DR problem is the first sub-task: synthesis of relevant information that could answer a user‚Äôs question, given a document corpus. The information synthesis problem can be conceptualized as a directed acyclic graph (DAG), where the nodes represent information such as original query, retrieved documents and synthesized information while the edges represent actions such as', 'score': 0.15575814, 'raw_content': None}, {'url': 'https://2025.aclweb.org/program/find_papers/', 'title': 'Accepted Findings Papers', 'content': 'Revisiting ``The Geometry of Truth‚Äô‚Äô: Emergent Consistent Linear Representation of Truthfulness in Capable Language ModelsYuntai Bao, Tianyu Du, Xuhong Zhang, Xinkui Zhao, Zhengwen Feng, Jianwei Yin\\n Comparing Bad Apples to Good Oranges Aligning Large Language Models via Joint Preference OptimizationHritik Bansal, Ashima Suvarna, Gantavya Bhatt, Nanyun Peng, Kai-Wei Chang, Aditya Grover [...] TDCSA: LLM-Guided Top-Down Approach for Robust Citation Sentiment AnalysisFan Gao, Jieyang Peng, Xiaoming Tao, WANG Youzheng\\n DeepRTL2: A Versatile Model for RTL-Related TasksYi Liu, Hongji Zhang, Yunhao Zhou, Zhengyuan Shi, Changran XU, Qiang Xu\\n The Self-Improvement Paradox: Can Language Models Bootstrap Reasoning Capabilities without External Scaffolding?Yutao Sun, Mingshuai Chen, Tiancheng Zhao, Ruochen Xu, Zilun Zhang, Jianwei Yin [...] Self-Tuning: Instructing LLMs to Effectively Acquire New Knowledge through Self-TeachingXiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou, Yipeng Zhang, Haitao Mi, Helen M. Meng\\n QueryAttack: Jailbreaking Aligned Large Language Models Using Structured Non-natural Query LanguageQingsong Zou, Jingyu Xiao, Qing Li, Zhi Yan, Yuhang Wang, Li Xu, Wenxuan Wang, Kuofeng Gao, Ruoyu Li, Yong Jiang', 'score': 0.074157745, 'raw_content': None}], 'response_time': 5.75, 'request_id': 'a308a341-81cf-4f19-9781-fa53e224531b'})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Renjun Xu and Jingwen Peng are currently affiliated with the University of Warwick, as researchers involved in a project related to their paper.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 4372, 'total_tokens': 4400, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 2432}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHB3qWSq4Fg1ydh2SQSINqSQIpgA', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--dbfee159-93de-444c-a70a-a7205f9088d5-0', usage_metadata={'input_tokens': 4372, 'output_tokens': 28, 'total_tokens': 4400, 'input_token_details': {'audio': 0, 'cache_read': 2432}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"First Search only on Arxiv for 'A Comprehensive Survey of Deep Research' paper to find the authors, then after authors are available use Tavily to search to find out where they work now!\")]}\n",
        "\n",
        "async for chunk in simple_agent_graph.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        #if node == \"action\":\n",
        "          #print(f\"Tool Used: {values['messages'][0].name}\")\n",
        "        print(values[\"messages\"])\n",
        "\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ù Breakout Room #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7c8-Uyarh1v"
      },
      "source": [
        "## Part 1: LangSmith Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV3XeFOT1Sar"
      },
      "source": [
        "### Pre-processing for LangSmith"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wruQCuzewUuO"
      },
      "source": [
        "To do a little bit more preprocessing, let's wrap our LangGraph agent in a simple chain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "orYxBZXSxJjZ",
        "outputId": "76be837b-6424-4516-8f63-07fbd8c25bf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'answer': 'Deep Research is a tool designed to perform advanced, in-depth research and analysis across the web. It can independently discover, reason about, and consolidate insights from multiple sources to generate comprehensive reports on various topics within minutes. This tool is useful for conducting detailed literature reviews, case studies, and complex research tasks by browsing the web, synthesizing information, and providing precise and thorough reports.'}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def convert_inputs(input_object):\n",
        "  return {\"messages\" : [HumanMessage(content=input_object[\"text\"])]}\n",
        "\n",
        "def parse_output(input_state):\n",
        "  return {\"answer\" : input_state[\"messages\"][-1].content}\n",
        "\n",
        "agent_chain_with_formatting = convert_inputs | simple_agent_graph | parse_output\n",
        "\n",
        "agent_chain_with_formatting.invoke({\"text\" : \"What is Deep Research?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9UkCIqkpyZu"
      },
      "source": [
        "### Task 1: Creating An Evaluation Dataset\n",
        "\n",
        "Just as we saw last week, we'll want to create a dataset to test our Agent's ability to answer questions.\n",
        "\n",
        "In order to do this - we'll want to provide some questions and some answers. Let's look at how we can create such a dataset below.\n",
        "\n",
        "```python\n",
        "questions = [\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Who were the main authors on the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' paper?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Peng\", \"Xu\"]}   \n",
        "    },\n",
        "    ...,\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"Where do the authors of the 'A Comprehensive Survey of Deep Research: Systems, Methodologies, and Applications' work now?\"},\n",
        "        \"outputs\" : {\"must_mention\" : [\"Zhejiang\", \"Liberty Mutual\"]}\n",
        "    }\n",
        "]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfMXF2KAsQxs"
      },
      "source": [
        "#### üèóÔ∏è Activity #3:\n",
        "\n",
        "Please create a dataset in the above format with at least 5 questions that pertain to the cohort use-case (more information [here](https://www.notion.so/Session-4-RAG-with-LangGraph-OSS-Local-Models-Eval-w-LangSmith-26acd547af3d80838d5beba464d7e701#26acd547af3d81d08809c9c82a462bdd)), or the use-case you're hoping to tackle in your Demo Day project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "CbagRuJop83E"
      },
      "outputs": [],
      "source": [
        "questions = [\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"What are the key bnefits of using AI at work?\"},\n",
        "        \"outputs\" : {\"must_mention_improved\" : [\"efficiency\", \"speed\"]}   \n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"What are the most common ways people use AI in their work?\"},\n",
        "        \"outputs\" : {\"must_mention_improved\" : [\"Search\", \"Retrieve\",\"Generate\"]}   \n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"What are the various use cases per domain that AI can be leveraged to great effect?\"},\n",
        "        \"outputs\" : {\"must_mention_improved\" : [\"Healthcare\", \"finance\", \"education\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"What concerns or challenges do people have when using AI?\"},\n",
        "        \"outputs\" : {\"must_mention_improved\" : [\"privacy\", \"cost\"]}\n",
        "    },\n",
        "    {\n",
        "        \"inputs\" : {\"text\" : \"How can these concerns people have about AI be mitigated?\"},\n",
        "        \"outputs\" : {\"must_mention_improved\" : [\"Regulations\", \"Ethics\", \"Transparency\"]}\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7QVFuAmsh7L"
      },
      "source": [
        "Now we can add our dataset to our LangSmith project using the following code which we saw last Thursday!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "RLfrZrgSsn85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'example_ids': ['4f4b42eb-10a3-494a-88bf-c0edaed7e53b',\n",
              "  'f69268b1-7132-42c3-b85e-4dd323bcdba3',\n",
              "  '13d93509-ec51-48d6-9a86-9182c6a9a058',\n",
              "  '342dc188-752e-4eef-8c2e-c421b733c4d5',\n",
              "  '1bf75396-09a6-465a-a653-602dc9823c35'],\n",
              " 'count': 5}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "\n",
        "dataset_name = f\"Simple Search Agent - Evaluation Dataset - {uuid4().hex[0:8]}\"\n",
        "\n",
        "dataset = client.create_dataset(\n",
        "    dataset_name=dataset_name,\n",
        "    description=\"Questions about the cohort use-case to evaluate the Simple Search Agent.\"\n",
        ")\n",
        "\n",
        "client.create_examples(\n",
        "    dataset_id=dataset.id,\n",
        "    examples=questions\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lRTXUrTtP9Y"
      },
      "source": [
        "### Task 2: Adding Evaluators\n",
        "\n",
        "Let's use the OpenEvals library to product an evaluator that we can then pass into LangSmith!\n",
        "\n",
        "> NOTE: Examine the `CORRECTNESS_PROMPT` below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert data labeler evaluating model outputs for correctness. Your task is to assign a score based on the following rubric:\n",
            "\n",
            "<Rubric>\n",
            "  A correct answer:\n",
            "  - Provides accurate and complete information\n",
            "  - Contains no factual errors\n",
            "  - Addresses all parts of the question\n",
            "  - Is logically consistent\n",
            "  - Uses precise and accurate terminology\n",
            "\n",
            "  When scoring, you should penalize:\n",
            "  - Factual errors or inaccuracies\n",
            "  - Incomplete or partial answers\n",
            "  - Misleading or ambiguous statements\n",
            "  - Incorrect terminology\n",
            "  - Logical inconsistencies\n",
            "  - Missing key information\n",
            "</Rubric>\n",
            "\n",
            "<Instructions>\n",
            "  - Carefully read the input and output\n",
            "  - Check for factual accuracy and completeness\n",
            "  - Focus on correctness of information rather than style or verbosity\n",
            "</Instructions>\n",
            "\n",
            "<Reminder>\n",
            "  The goal is to evaluate factual correctness and completeness of the response.\n",
            "</Reminder>\n",
            "\n",
            "<input>\n",
            "{inputs}\n",
            "</input>\n",
            "\n",
            "<output>\n",
            "{outputs}\n",
            "</output>\n",
            "\n",
            "Use the reference outputs below to help you evaluate the correctness of the response:\n",
            "\n",
            "<reference_outputs>\n",
            "{reference_outputs}\n",
            "</reference_outputs>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from openevals.prompts import CORRECTNESS_PROMPT\n",
        "print(CORRECTNESS_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "QrAUXMFftlAY"
      },
      "outputs": [],
      "source": [
        "from openevals.llm import create_llm_as_judge\n",
        "\n",
        "correctness_evaluator = create_llm_as_judge(\n",
        "        prompt=CORRECTNESS_PROMPT,\n",
        "        model=\"openai:o3-mini\", # very impactful to the final score\n",
        "        feedback_key=\"correctness\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's also create a custom Evaluator for our created dataset above - we do this by first making a simple Python function!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 1.00 (100.0%)\n",
            "Found: 3 out of 3 required phrases\n"
          ]
        }
      ],
      "source": [
        "def must_mention_improved(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
        "  \"\"\"\n",
        "  Improved version that returns True if ANY of the required phrases are found in the answer.\n",
        "  Uses 'any()' instead of 'all()' to be more lenient and compatible with LangSmith boolean evaluators.\n",
        "  \"\"\"\n",
        "  # Get the required phrases from reference_outputs\n",
        "  required = reference_outputs.get(\"must_mention\") or []\n",
        "  \n",
        "  # If no phrases are required, return True (perfect score)\n",
        "  if not required:\n",
        "    return True\n",
        "  \n",
        "  # Get the answer text (convert to lowercase for case-insensitive matching)\n",
        "  answer_text = outputs[\"answer\"].lower()\n",
        "  \n",
        "  # Return True if ANY of the required phrases are found in the answer\n",
        "  return any(phrase.lower() in answer_text for phrase in required)\n",
        "\n",
        "# Example usage and testing\n",
        "test_inputs = {\"text\": \"What are the main authors of the Deep Research paper?\"}\n",
        "test_outputs = {\"answer\": \"The main authors are Renjun Xu and Jingwen Peng from Zhejiang University.\"}\n",
        "test_reference = {\"must_mention\": [\"Renjun Xu\", \"Jingwen Peng\", \"Zhejiang University\"]}\n",
        "\n",
        "# Test the improved function\n",
        "result = must_mention_improved(test_inputs, test_outputs, test_reference)\n",
        "print(f\"Result: {result}\")\n",
        "print(f\"Found at least one required phrase: {'Yes' if result else 'No'}\")\n",
        "\n",
        "# Test with partial match\n",
        "test_outputs_partial = {\"answer\": \"The author is Renjun Xu.\"}\n",
        "result_partial = must_mention_improved(test_inputs, test_outputs_partial, test_reference)\n",
        "print(f\"Partial match result: {result_partial}\")\n",
        "\n",
        "# Test with no match\n",
        "test_outputs_none = {\"answer\": \"The authors are Smith and Jones.\"}\n",
        "result_none = must_mention_improved(test_inputs, test_outputs_none, test_reference)\n",
        "print(f\"No match result: {result_none}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def must_mention(inputs: dict, outputs: dict, reference_outputs: dict) -> float:\n",
        "  # determine if the phrases in the reference_outputs are in the outputs\n",
        "  required = reference_outputs.get(\"must_mention\") or []\n",
        "  score = all(phrase in outputs[\"answer\"] for phrase in required)\n",
        "  return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNtHORUh0jZY"
      },
      "source": [
        "#### ‚ùì Question #4:\n",
        "\n",
        "What are some ways you could improve this metric as-is?\n",
        "\n",
        "> NOTE: Alternatively you can suggest where gaps exist in this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### ‚úÖ Answer: \n",
        "Instead of must mention which is an exact word search- it should check for semantic similarity  to the must have words. Also it seems it is checkign for all the words to exist, the answer can still be correct with only some of the words.\n",
        "other ways:\n",
        "Ask for cited sources of answers to be able to compare that the answer provided is indeed supported by the provided documents\n",
        "Check for relaevance of answers to the query (uses LLM again)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1RJr349zhv7"
      },
      "source": [
        "Task 3: Evaluating\n",
        "\n",
        "All that is left to do is evaluate our agent's response!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "efcf57067cf743d8b4ce059a61cbe02e",
            "53e33aae3b97490c82aec7bbb0d6ebba",
            "ad84e0e971d3455db2efe7dd0d1f803e",
            "72adef9b70dd48198b7322b6c5b113cf",
            "8a61d045ffd44ac58f3f13eb10044836",
            "041e22a9b5514e36bd4d1dac01d5d398",
            "886d762f2a7c421382efb5502c6d42a1",
            "ab91fd625bbd43afbf8c6398193a88d0",
            "716557ad09874dcb989d75f7c74424cd",
            "77d4c0ebaae045b58efc4f789c9a2360",
            "0d622ccc56264fac8fd7508dbdbe6e29"
          ]
        },
        "id": "p5TeCUUkuGld",
        "outputId": "2f7d62a2-e78d-447a-d07b-f9e4d500fb79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "View the evaluation results for experiment: 'simple_agent, baseline-10e5039f' at:\n",
            "https://smith.langchain.com/o/4528ad4f-8895-4efc-95a1-834ac718fac4/datasets/98066dbc-11be-44e6-a641-5609074ff29f/compare?selectedSessions=f6af7213-629c-41d9-b8c4-a60657cc80b4\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "987186dde8f043a999c20bce6b0ec38c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = client.evaluate(\n",
        "    agent_chain_with_formatting,\n",
        "    data=dataset.name,\n",
        "    #evaluators=[correctness_evaluator, must_mention],\n",
        "    evaluators=[correctness_evaluator, must_mention_improved],\n",
        "    experiment_prefix=\"simple_agent, baseline\",  # optional, experiment name prefix\n",
        "    description=\"Testing the baseline system.\",  # optional, experiment description\n",
        "    max_concurrency=4, # optional, add concurrency\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTNe4kWrplB"
      },
      "source": [
        "## Part 2: LangGraph with Helpfulness:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1wKRddbIY_S"
      },
      "source": [
        "### Task 3: Adding Helpfulness Check and \"Loop\" Limits\n",
        "\n",
        "Now that we've done evaluation - let's see if we can add an extra step where we review the content we've generated to confirm if it fully answers the user's query!\n",
        "\n",
        "We're going to make a few key adjustments to account for this:\n",
        "\n",
        "1. We're going to add an artificial limit on how many \"loops\" the agent can go through - this will help us to avoid the potential situation where we never exit the loop.\n",
        "2. We'll add to our existing conditional edge to obtain the behaviour we desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTYJ8ayR5B3"
      },
      "source": [
        "First, let's define our state again - we can check the length of the state object, so we don't need additional state for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-LQ84YhyJG0w"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "  messages: Annotated[list, add_messages]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD7EV0HqSQcb"
      },
      "source": [
        "Now we can set our graph up! This process will be almost entirely the same - with the inclusion of one additional node/conditional edge!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oajBwLkFVi1N"
      },
      "source": [
        "#### üèóÔ∏è Activity #4:\n",
        "\n",
        "Please write markdown for the following cells to explain what each is doing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6rN7feNVn9f"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "### Creating the Enhanced Graph with Helpfulness Check\n",
        "\n",
        "This code initializes a new `StateGraph` that includes an additional helpfulness checking mechanism to ensure the agent provides complete and useful responses.\n",
        "\n",
        "**What this code does:**\n",
        "\n",
        "1. **`graph_with_helpfulness_check = StateGraph(AgentState)`**\n",
        "   - Creates a new state graph using the same `AgentState` structure as the basic agent\n",
        "   - This graph will be enhanced with helpfulness checking capabilities\n",
        "\n",
        "2. **`graph_with_helpfulness_check.add_node(\"agent\", call_model)`**\n",
        "   - Adds the \"agent\" node that calls the language model\n",
        "   - This is the same as the basic agent - it processes messages and decides whether to use tools\n",
        "\n",
        "3. **`graph_with_helpfulness_check.add_node(\"action\", tool_node)`**\n",
        "   - Adds the \"action\" node that executes tools when needed\n",
        "   - This handles the actual tool execution (search, arxiv, etc.)\n",
        "\n",
        "**Key Difference from Basic Agent:**\n",
        "This enhanced graph will later include additional logic to:\n",
        "- Check if the agent's response is helpful enough\n",
        "- Add loop limits to prevent infinite cycles\n",
        "- Provide more intelligent stopping conditions\n",
        "\n",
        "The graph structure starts the same as the basic agent but will be enhanced with conditional edges that evaluate response quality before deciding whether to continue or stop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r6XXA5FJbVf",
        "outputId": "ff713041-e498-4f0f-a875-a03502b87729"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c102fd0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check = StateGraph(AgentState)\n",
        "\n",
        "graph_with_helpfulness_check.add_node(\"agent\", call_model)\n",
        "graph_with_helpfulness_check.add_node(\"action\", tool_node)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ22o2mWVrfp"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "### Setting the Entry Point for the Enhanced Graph\n",
        "\n",
        "This line establishes where the graph execution begins when a new conversation or query is processed.\n",
        "\n",
        "**What this code does:**\n",
        "\n",
        "- **`set_entry_point(\"agent\")`** - Designates the \"agent\" node as the starting point for all graph executions\n",
        "- When a user sends a message, the graph will always begin by routing to the \"agent\" node first\n",
        "- The agent node will then decide the next steps based on the input and current state\n",
        "\n",
        "**Why start with the agent node?**\n",
        "\n",
        "1. **Natural Flow**: The agent (LLM) is the \"brain\" that analyzes the user's request\n",
        "2. **Decision Making**: The agent determines whether tools are needed or if it can respond directly\n",
        "3. **State Management**: The agent processes the conversation history and maintains context\n",
        "4. **Routing Logic**: Based on the agent's analysis, the graph will route to either:\n",
        "   - The \"action\" node (if tools are needed)\n",
        "   - The helpfulness check (if a response is ready)\n",
        "   - The end (if the response is complete and helpful)\n",
        "\n",
        "**Graph Flow:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNWHwWxuRiLY",
        "outputId": "295f5a35-ceff-452a-ffb8-c52eada6a816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c102fd0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.set_entry_point(\"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXeF6xlaXOZ"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "### Conditional Edge Function: Tool Call or Helpfulness Check\n",
        "\n",
        "### Conditional Edge Function: Tool Call or Helpfulness Check\n",
        "\n",
        "This function serves as a sophisticated decision-making node that determines the next step in the graph based on the current state of the conversation.\n",
        "\n",
        "**Function Purpose:**\n",
        "The `tool_call_or_helpful` function implements intelligent routing logic that decides whether to:\n",
        "1. Execute tools (if needed)\n",
        "2. Check response helpfulness (if response is ready)\n",
        "3. End the conversation (if response is helpful or max iterations reached)\n",
        "\n",
        "**Step-by-Step Logic:**\n",
        "\n",
        "1. **Tool Call Detection:**\n",
        "   ```python\n",
        "   if last_message.tool_calls:\n",
        "       return \"action\"\n",
        "   ```\n",
        "   - If the last message contains tool calls, route to the \"action\" node\n",
        "   - This ensures tools are executed when the agent decides they're needed\n",
        "\n",
        "2. **Loop Limit Protection:**\n",
        "   ```python\n",
        "   if len(state[\"messages\"]) > 10:\n",
        "       return \"END\"\n",
        "   ```\n",
        "   - Prevents infinite loops by limiting conversation to 10 messages\n",
        "   - Safety mechanism to avoid runaway conversations\n",
        "\n",
        "3. **Helpfulness Evaluation:**\n",
        "   ```python\n",
        "   initial_query = state[\"messages\"][0]      # Original user question\n",
        "   final_response = state[\"messages\"][-1]    # Most recent response\n",
        "   ```\n",
        "   - **Extracts the original user query** (first message in the conversation)\n",
        "   - **Extracts the last response** (most recent message, which is the agent's current response)\n",
        "   - Uses a separate LLM to evaluate if this last response adequately addresses the original query\n",
        "\n",
        "4. **Response Processing:**\n",
        "   ```python\n",
        "   if \"Y\" in helpfulness_response:\n",
        "       return \"end\"  # Last response is helpful, end conversation\n",
        "   else:\n",
        "       return \"continue\"  # Last response needs improvement, try again\n",
        "   ```\n",
        "\n",
        "**Key Insight:**\n",
        "The function compares the **original user question** against the **most recent agent response** to determine if the agent has provided a satisfactory answer. If not, it routes back to the agent to try generating a better response.\n",
        "\n",
        "**Graph Flow:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "z_Sq3A9SaV1O"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def tool_call_or_helpful(state):\n",
        "  last_message = state[\"messages\"][-1]\n",
        "\n",
        "  if last_message.tool_calls:\n",
        "    return \"action\"\n",
        "\n",
        "  initial_query = state[\"messages\"][0]\n",
        "  final_response = state[\"messages\"][-1]\n",
        "\n",
        "  if len(state[\"messages\"]) > 10:\n",
        "    return \"END\"\n",
        "\n",
        "  prompt_template = \"\"\"\\\n",
        "  Given an initial query and a final response, determine if the final response is extremely helpful or not. Please indicate helpfulness with a 'Y' and unhelpfulness as an 'N'.\n",
        "\n",
        "  Initial Query:\n",
        "  {initial_query}\n",
        "\n",
        "  Final Response:\n",
        "  {final_response}\"\"\"\n",
        "\n",
        "  helpfullness_prompt_template = PromptTemplate.from_template(prompt_template)\n",
        "\n",
        "  helpfulness_check_model = ChatOpenAI(model=\"gpt-4.1-mini\")\n",
        "\n",
        "  helpfulness_chain = helpfullness_prompt_template | helpfulness_check_model | StrOutputParser()\n",
        "\n",
        "  helpfulness_response = helpfulness_chain.invoke({\"initial_query\" : initial_query.content, \"final_response\" : final_response.content})\n",
        "\n",
        "  if \"Y\" in helpfulness_response:\n",
        "    return \"end\"\n",
        "  else:\n",
        "    return \"continue\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BhnBW2YVsJO"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "### Adding Conditional Edges to the Enhanced Graph\n",
        "\n",
        "This code creates the intelligent routing system that determines the flow of the conversation based on the agent's responses and tool usage decisions.\n",
        "\n",
        "**What this code does:**\n",
        "\n",
        "- **`add_conditional_edges(\"agent\", tool_call_or_helpful, {...})`** - Creates conditional routing from the \"agent\" node\n",
        "- The `tool_call_or_helpful` function acts as the decision-maker\n",
        "- The dictionary maps possible return values to destination nodes\n",
        "\n",
        "**Routing Logic:**\n",
        "\n",
        "1. **`\"continue\" : \"agent\"`**\n",
        "   - When the helpfulness check determines the response needs improvement\n",
        "   - Routes back to the agent node to generate a better response\n",
        "   - Creates a feedback loop for response refinement\n",
        "\n",
        "2. **`\"action\" : \"action\"`**\n",
        "   - When the agent decides to use tools (tool_calls detected)\n",
        "   - Routes to the action node to execute the required tools\n",
        "   - Enables external data gathering and processing\n",
        "\n",
        "3. **`\"end\" : END`**\n",
        "   - When the response is deemed helpful and complete or max conv has been reached\n",
        "   - Terminates the conversation flow\n",
        "   - Prevents unnecessary iterations\n",
        "\n",
        "**Graph Flow Visualization:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVTKnWMbP_8T",
        "outputId": "7f729b1f-311c-4084-ceaf-0da437900c85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c102fd0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_conditional_edges(\n",
        "    \"agent\",\n",
        "    tool_call_or_helpful,\n",
        "    {\n",
        "        \"continue\" : \"agent\",\n",
        "        \"action\" : \"action\",\n",
        "        \"end\" : END\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGDLEWOIVtK0"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "### Adding the Action-to-Agent Edge\n",
        "\n",
        "This code creates a direct connection from the action node back to the agent node, completing the tool execution cycle.\n",
        "\n",
        "**What this code does:**\n",
        "\n",
        "- **`add_edge(\"action\", \"agent\")`** - Creates a direct, unconditional edge from \"action\" to \"agent\"\n",
        "- After tools are executed, the results always flow back to the agent for processing\n",
        "- This ensures the agent can analyze tool outputs and decide the next steps\n",
        "\n",
        "**Why this edge is essential:**\n",
        "\n",
        "1. **Tool Result Processing**: After executing tools (search, arxiv, etc.), the results need to be analyzed\n",
        "2. **Context Integration**: The agent incorporates tool outputs into its understanding\n",
        "3. **Next Decision Point**: The agent decides whether to:\n",
        "   - Use the tool results to answer the user\n",
        "   - Execute additional tools if needed\n",
        "   - End the conversation if satisfied\n",
        "\n",
        "**Complete Graph Flow:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbDK2MbuREgU",
        "outputId": "21a64c20-27a1-4e0e-afde-a639abaa8b55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x11c102fd0>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph_with_helpfulness_check.add_edge(\"action\", \"agent\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSI8AOaEVvT-"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "### Compiling the Enhanced Graph into an Executable Agent\n",
        "\n",
        "This line transforms the graph definition into a runnable agent that can process user inputs and execute the complete conversation flow.\n",
        "\n",
        "**What this code does:**\n",
        "\n",
        "- **`graph_with_helpfulness_check.compile()`** - Converts the graph structure into an executable agent\n",
        "- **`agent_with_helpfulness_check =`** - Assigns the compiled agent to a variable for use\n",
        "- The agent is now ready to process inputs and execute the full conversation logic\n",
        "\n",
        "**What happens during compilation:**\n",
        "\n",
        "1. **Graph Validation**: Ensures all nodes and edges are properly connected\n",
        "2. **State Management**: Sets up the AgentState handling system\n",
        "3. **Execution Engine**: Creates the runtime that can process streaming inputs\n",
        "4. **Error Handling**: Prepares the agent for robust execution\n",
        "\n",
        "**Key Capabilities of the Compiled Agent:**\n",
        "\n",
        "- **Streaming Support**: Can process inputs with `astream()` for real-time updates\n",
        "- **State Persistence**: Maintains conversation context across multiple interactions\n",
        "- **Tool Integration**: Seamlessly executes external tools when needed\n",
        "- **Helpfulness Checking**: Automatically evaluates response quality\n",
        "- **Loop Protection**: Prevents infinite conversations with built-in limits\n",
        "\n",
        "**Usage:**\n",
        "```python\n",
        "# The agent is now ready to use\n",
        "inputs = {\"messages\": [HumanMessage(content=\"Your question here\")]}\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    # Process streaming updates\n",
        "```\n",
        "\n",
        "**From Graph to Agent:**\n",
        "- **Before Compilation**: Graph definition (nodes, edges, conditions)\n",
        "- **After Compilation**: Executable agent with full conversation logic\n",
        "- **Result**: A sophisticated AI agent that can reason, use tools, and self-evaluate\n",
        "\n",
        "This compiled agent represents the complete implementation of an intelligent conversational AI with built-in quality control and tool usage capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "oQldl8ERQ8lf"
      },
      "outputs": [],
      "source": [
        "agent_with_helpfulness_check = graph_with_helpfulness_check.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F67FGCMRVwGz"
      },
      "source": [
        "##### YOUR MARKDOWN HERE\n",
        "### Testing the Enhanced Agent with Helpfulness Check\n",
        "\n",
        "This code demonstrates the enhanced agent in action, showing how it processes a query with built-in helpfulness evaluation and tool usage capabilities.\n",
        "\n",
        "**What this code does:**\n",
        "\n",
        "1. **Input Preparation:**\n",
        "   ```python\n",
        "   inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
        "   ```\n",
        "   - Creates a conversation input with a specific question about Deep Research Agents\n",
        "   - Wraps the question in a `HumanMessage` object for proper state management\n",
        "\n",
        "2. **Streaming Execution:**\n",
        "   ```python\n",
        "   async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "   ```\n",
        "   - Uses the compiled enhanced agent with helpfulness checking\n",
        "   - Streams updates in real-time as the agent processes the request\n",
        "   - `stream_mode=\"updates\"` provides updates when each node completes\n",
        "\n",
        "3. **Real-time Monitoring:**\n",
        "   ```python\n",
        "   for node, values in chunk.items():\n",
        "       print(f\"Receiving update from node: '{node}'\")\n",
        "       print(values[\"messages\"])\n",
        "       print(\"\\n\\n\")\n",
        "   ```\n",
        "   - Displays which node is currently executing\n",
        "   - Shows the messages being processed at each step\n",
        "   - Provides visibility into the agent's decision-making process\n",
        "\n",
        "**Expected Flow:**\n",
        "1. **Agent Node**: Analyzes the question about Deep Research Agents\n",
        "2. **Decision Point**: Determines if tools are needed or can answer directly\n",
        "3. **Tool Execution** (if needed): Searches for relevant information\n",
        "4. **Helpfulness Check**: Evaluates if the response adequately answers the question\n",
        "5. **Final Response**: Either provides the answer or continues refining\n",
        "\n",
        "**Key Benefits Demonstrated:**\n",
        "- **Transparency**: You can see exactly what the agent is doing at each step\n",
        "- **Quality Control**: The agent evaluates its own responses for helpfulness\n",
        "- **Tool Integration**: Seamlessly uses external tools when needed\n",
        "- **Iterative Improvement**: Can refine responses if not initially helpful enough\n",
        "\n",
        "This execution showcases the sophisticated conversation flow of the enhanced agent with built-in quality assurance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3oo8E-PRK1T",
        "outputId": "f152dea8-96ad-4d29-d8b2-a064c96a8bd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_pCxqnm2cGFrWRQLXYOtJfOQt', 'function': {'arguments': '{\"query\": \"Deep Research Agents\"}', 'name': 'tavily_search_results_json'}, 'type': 'function'}, {'id': 'call_54Nbi9UchSrJozMymUalyGnc', 'function': {'arguments': '{\"query\": \"Deep Research Agents\"}', 'name': 'duckduckgo_search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 208, 'total_tokens': 263, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHBUJRSljzrnRnpqxwuj4vSMBcnK', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b206e62e-0b58-4ec8-b0b1-68cf3d2207df-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Deep Research Agents'}, 'id': 'call_pCxqnm2cGFrWRQLXYOtJfOQt', 'type': 'tool_call'}, {'name': 'duckduckgo_search', 'args': {'query': 'Deep Research Agents'}, 'id': 'call_54Nbi9UchSrJozMymUalyGnc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 208, 'output_tokens': 55, 'total_tokens': 263, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'action'\n",
            "[ToolMessage(content='[{\"title\": \"Deep Research | FlowiseAI - Flowise documentation\", \"url\": \"https://docs.flowiseai.com/tutorials/deep-research\", \"content\": \"Edit\\\\n\\\\n# Deep Research\\\\n\\\\nDeep Research Agent is a sophisticated multi-agent system that can conduct comprehensive research on any topic by breaking down complex queries into manageable tasks, deploying specialized research agents, and synthesizing findings into detailed reports.\\\\n\\\\nThis approach is inspired by Anthropic\\'s blog - How we built our multi-agent research system\\\\n\\\\n## Overview\\\\n\\\\nThe Deep Research Agent workflow consists of several key components working together:\", \"score\": 0.93511593}, {\"title\": \"Deep Research Agents: A Systematic Examination And Roadmap\", \"url\": \"https://arxiv.org/html/2506.18096v1\", \"content\": \"Report issue for preceding element\\\\n\\\\nFormally, we define ‚ÄúDeep Research Agents‚Äù as:\\\\n\\\\nReport issue for preceding element\\\\n\\\\nAI agents powered by LLMs, integrating dynamic reasoning, adaptive planning, multi-iteration external data retrieval and tool use, and comprehensive analytical report generation for informational research tasks.\\\\n\\\\nReport issue for preceding element [...] advanced autonomous systems, termed Deep Research (DR) agents, has emerged, exemplified by industry-leading solutions such as OpenAI DRopenai2025deepresearch, Gemini DRgeminideepresearch, Grok DeepSearchgrokdeepresearch, and Perplexity DRperplexitydeepresearch. These deep research agents significantly extend LLMs by incorporating advanced reasoning, dynamic task planning, and adaptive interaction with web resources and analytical tools. [...] Compared with traditional Retrieval-Augmented Generation (RAG) methodssingh2025agentic, which primarily enhance factual accuracy but lack sustained reasoning capabilitieschen2025improving, and conventional Tool Use (TU) systemsqu2025tool that heavily depend on pre-defined workflowswang2025tdag, DR agents offer significantly greater autonomy, continual and deep reasoning abilities, dynamic task planning, and adaptive real-time interaction. These advanced capabilities uniquely position DR agents\", \"score\": 0.9126935}, {\"title\": \"Deep Research Agents: A Systematic Examination And ...\", \"url\": \"https://arxiv.org/abs/2506.18096\", \"content\": \"> Abstract:The rapid progress of Large Language Models (LLMs) has given rise to a new category of autonomous AI systems, referred to as Deep Research (DR) agents. These agents are designed to tackle complex, multi-turn informational research tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon planning, multi-hop information retrieval, iterative tool use, and the generation of structured analytical reports. In this paper, we conduct a detailed analysis of the [...] Authors:Yuxuan Huang, Yihang Chen, Haozheng Zhang, Kang Li, Huichi Zhou, Meng Fang, Linyi Yang, Xiaoguang Li, Lifeng Shang, Songcen Xu, Jianye Hao, Kun Shao, Jun Wang\\\\n\\\\nView a PDF of the paper titled Deep Research Agents: A Systematic Examination And Roadmap, by Yuxuan Huang and 12 other authors [...] foundational technologies and architectural components that constitute Deep Research agents. We begin by reviewing information acquisition strategies, contrasting API-based retrieval methods with browser-based exploration. We then examine modular tool-use frameworks, including code execution, multimodal input processing, and the integration of Model Context Protocols (MCPs) to support extensibility and ecosystem development. To systematize existing approaches, we propose a taxonomy that\", \"score\": 0.8790744}, {\"title\": \"OpenAI\\'s Deep Research on Training AI Agents End-to-End\", \"url\": \"https://www.sequoiacap.com/podcast/training-data-deep-research/\", \"content\": \"Isa Fulford: So Deep Research is an agent that is able to search many online websites, and it can create very comprehensive reports. It can do tasks that would take humans many hours to complete. And it‚Äôs in ChatGPT, and it takes like five to thirty minutes to answer you. And so it‚Äôs able to do much more in-depth research and answer your questions with much more detail and specific sources than regular ChatGPT response would be able to do.\", \"score\": 0.86108357}, {\"title\": \"Understanding the AI Agent Tool Deep Research\", \"url\": \"https://builtin.com/articles/understanding-chatgpt-deep-research\", \"content\": \"## What Is Deep Research?\\\\n\\\\nDeep research is an agentic AI tool integrated into AI platforms like ChatGPT and Gemini, allowing it to perform context-rich investigations across multiple sources, domains and timeframes. It can browse online sources in real time, upload data sources and synthesize information into comprehensive reports. [...] Artificial Intelligence\\\\n Expert Contributors\\\\n Machine Learning\\\\n +1\\\\n Natural Language Processing\\\\n +3\\\\n\\\\n# Understanding the AI Agent Tool Deep Research\\\\n\\\\nDeep Research is an agentic AI tool integrated into AI platforms like ChatGPT to conduct context-rich investigations across multiple sources, domains and timeframes. Here‚Äôs what you need to know.\\\\n\\\\nWritten by\\\\nVinay Goel\\\\n\\\\nPublished on May. 20, 2025\\\\n\\\\nImage: Shutterstock / Built In [...] Deep research, a term for the AI agent tool integrated into ChatGPT, Gemini and other AI tools, can perform high-quality, context-rich investigations across multiple sources, domains, and timeframes. Unlike regular search engines or chatbots that provide quick answers or web links, deep research thinks like an actual human. It actively browses online sources in real time, internally uploads data sources, checks multiple references and synthesizes information into comprehensive reports. Its\", \"score\": 0.85825616}]', name='tavily_search_results_json', id='322c45bd-22c8-4c42-89c8-b76362d4447d', tool_call_id='call_pCxqnm2cGFrWRQLXYOtJfOQt', artifact={'query': 'Deep Research Agents', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'url': 'https://docs.flowiseai.com/tutorials/deep-research', 'title': 'Deep Research | FlowiseAI - Flowise documentation', 'content': \"Edit\\n\\n# Deep Research\\n\\nDeep Research Agent is a sophisticated multi-agent system that can conduct comprehensive research on any topic by breaking down complex queries into manageable tasks, deploying specialized research agents, and synthesizing findings into detailed reports.\\n\\nThis approach is inspired by Anthropic's blog - How we built our multi-agent research system\\n\\n## Overview\\n\\nThe Deep Research Agent workflow consists of several key components working together:\", 'score': 0.93511593, 'raw_content': None}, {'url': 'https://arxiv.org/html/2506.18096v1', 'title': 'Deep Research Agents: A Systematic Examination And Roadmap', 'content': 'Report issue for preceding element\\n\\nFormally, we define ‚ÄúDeep Research Agents‚Äù as:\\n\\nReport issue for preceding element\\n\\nAI agents powered by LLMs, integrating dynamic reasoning, adaptive planning, multi-iteration external data retrieval and tool use, and comprehensive analytical report generation for informational research tasks.\\n\\nReport issue for preceding element [...] advanced autonomous systems, termed Deep Research (DR) agents, has emerged, exemplified by industry-leading solutions such as OpenAI DRopenai2025deepresearch, Gemini DRgeminideepresearch, Grok DeepSearchgrokdeepresearch, and Perplexity DRperplexitydeepresearch. These deep research agents significantly extend LLMs by incorporating advanced reasoning, dynamic task planning, and adaptive interaction with web resources and analytical tools. [...] Compared with traditional Retrieval-Augmented Generation (RAG) methodssingh2025agentic, which primarily enhance factual accuracy but lack sustained reasoning capabilitieschen2025improving, and conventional Tool Use (TU) systemsqu2025tool that heavily depend on pre-defined workflowswang2025tdag, DR agents offer significantly greater autonomy, continual and deep reasoning abilities, dynamic task planning, and adaptive real-time interaction. These advanced capabilities uniquely position DR agents', 'score': 0.9126935, 'raw_content': None}, {'url': 'https://arxiv.org/abs/2506.18096', 'title': 'Deep Research Agents: A Systematic Examination And ...', 'content': '> Abstract:The rapid progress of Large Language Models (LLMs) has given rise to a new category of autonomous AI systems, referred to as Deep Research (DR) agents. These agents are designed to tackle complex, multi-turn informational research tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon planning, multi-hop information retrieval, iterative tool use, and the generation of structured analytical reports. In this paper, we conduct a detailed analysis of the [...] Authors:Yuxuan Huang, Yihang Chen, Haozheng Zhang, Kang Li, Huichi Zhou, Meng Fang, Linyi Yang, Xiaoguang Li, Lifeng Shang, Songcen Xu, Jianye Hao, Kun Shao, Jun Wang\\n\\nView a PDF of the paper titled Deep Research Agents: A Systematic Examination And Roadmap, by Yuxuan Huang and 12 other authors [...] foundational technologies and architectural components that constitute Deep Research agents. We begin by reviewing information acquisition strategies, contrasting API-based retrieval methods with browser-based exploration. We then examine modular tool-use frameworks, including code execution, multimodal input processing, and the integration of Model Context Protocols (MCPs) to support extensibility and ecosystem development. To systematize existing approaches, we propose a taxonomy that', 'score': 0.8790744, 'raw_content': None}, {'url': 'https://www.sequoiacap.com/podcast/training-data-deep-research/', 'title': \"OpenAI's Deep Research on Training AI Agents End-to-End\", 'content': 'Isa Fulford: So Deep Research is an agent that is able to search many online websites, and it can create very comprehensive reports. It can do tasks that would take humans many hours to complete. And it‚Äôs in ChatGPT, and it takes like five to thirty minutes to answer you. And so it‚Äôs able to do much more in-depth research and answer your questions with much more detail and specific sources than regular ChatGPT response would be able to do.', 'score': 0.86108357, 'raw_content': None}, {'url': 'https://builtin.com/articles/understanding-chatgpt-deep-research', 'title': 'Understanding the AI Agent Tool Deep Research', 'content': '## What Is Deep Research?\\n\\nDeep research is an agentic AI tool integrated into AI platforms like ChatGPT and Gemini, allowing it to perform context-rich investigations across multiple sources, domains and timeframes. It can browse online sources in real time, upload data sources and synthesize information into comprehensive reports. [...] Artificial Intelligence\\n Expert Contributors\\n Machine Learning\\n +1\\n Natural Language Processing\\n +3\\n\\n# Understanding the AI Agent Tool Deep Research\\n\\nDeep Research is an agentic AI tool integrated into AI platforms like ChatGPT to conduct context-rich investigations across multiple sources, domains and timeframes. Here‚Äôs what you need to know.\\n\\nWritten by\\nVinay Goel\\n\\nPublished on May. 20, 2025\\n\\nImage: Shutterstock / Built In [...] Deep research, a term for the AI agent tool integrated into ChatGPT, Gemini and other AI tools, can perform high-quality, context-rich investigations across multiple sources, domains, and timeframes. Unlike regular search engines or chatbots that provide quick answers or web links, deep research thinks like an actual human. It actively browses online sources in real time, internally uploads data sources, checks multiple references and synthesizes information into comprehensive reports. Its', 'score': 0.85825616, 'raw_content': None}], 'response_time': 1.4, 'request_id': 'b41f8bfd-dcf4-4649-af53-dd1b4396d35d'}), ToolMessage(content=\"The rapid progress of Large Language Models (LLMs) has given rise to a new category of autonomous AI systems, referred to as Deep Research (DR) agents . These agents are designed to tackle complex, multi-turn informational research tasks by leveraging a combination of dynamic reasoning, adaptive long-horizon planning, multi-hop information retrieval, iterative tool use, and the generation of ... An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research tasks for you. Available to Pro users today, Plus and Team next. The Deep Research tool in the Azure AI Foundry Agent Service enables you to integrate a web-based research capability into your systems. The Deep Research capability is a specialized AI capability designed to perform in-depth, multi-step research using data from the public web. AI agents are evolving beyond basic single-task helpers into more powerful systems that can plan, critique, and collaborate with other agents to solve complex problems. Deep Agents‚Äîa recently introduced framework built on LangGraph‚Äîbring these capabilities to life, enabling multi- agent workflows that mirror real-world team dynamics. The challenge, however, is not just building such agents ... Welcome to Awesome- Deep - Research ! üöÄ This repository serves as your comprehensive guide to the cutting-edge world of Agentic Deep Research . We've meticulously curated a collection of resources for you. Whether you're a researcher, developer, or enthusiast, this repository is your gateway to exploring the fascinating intersection of artificial intelligence and autonomous agents . For a ...\", name='duckduckgo_search', id='7c4c6e6f-5082-40dd-8777-1e6c6824ce7e', tool_call_id='call_54Nbi9UchSrJozMymUalyGnc')]\n",
            "\n",
            "\n",
            "\n",
            "Receiving update from node: 'agent'\n",
            "[AIMessage(content='Deep Research Agents are advanced autonomous AI systems designed to perform comprehensive and complex research tasks. They leverage large language models (LLMs) and incorporate features such as dynamic reasoning, adaptive long-horizon planning, multi-hop information retrieval, iterative tool use, and structured report generation. These agents can actively browse online sources in real time, synthesize information from multiple references, and produce detailed analytical reports.\\n\\nThey are capable of handling multi-turn informational research, making them suitable for tasks that require deep understanding and multi-step reasoning across various sources and domains. Deep Research Agents are used in various applications, including in platforms like ChatGPT and Gemini, to conduct context-rich investigations, extend the capabilities of traditional search and retrieval systems, and automate complex research workflows.\\n\\nIn summary, Deep Research Agents are sophisticated AI tools that mimic human-like research processes to gather, analyze, and synthesize large amounts of online information efficiently and effectively.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 181, 'prompt_tokens': 1775, 'total_tokens': 1956, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_7c233bf9d1', 'id': 'chatcmpl-CLHBXFY0chA4A8QsFOkam74BBclnD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--63b83237-23c0-44c6-a761-b063d9ec4bf6-0', usage_metadata={'input_tokens': 1775, 'output_tokens': 181, 'total_tokens': 1956, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "inputs = {\"messages\" : [HumanMessage(content=\"What are Deep Research Agents?\")]}\n",
        "\n",
        "async for chunk in agent_with_helpfulness_check.astream(inputs, stream_mode=\"updates\"):\n",
        "    for node, values in chunk.items():\n",
        "        print(f\"Receiving update from node: '{node}'\")\n",
        "        print(values[\"messages\"])\n",
        "        print(\"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVmZPs6lnpsM"
      },
      "source": [
        "## Part 3: LangGraph for the \"Patterns\" of GenAI\n",
        "\n",
        "### Task 4: Helpfulness Check of Gen AI Pattern Descriptions\n",
        "\n",
        "Let's ask our system about the 3 main patterns in Generative AI:\n",
        "\n",
        "1. Context Engineering\n",
        "2. Fine-tuning\n",
        "3. Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ZoLl7GlXoae-"
      },
      "outputs": [],
      "source": [
        "patterns = [\"Context Engineering\", \"Fine-tuning\", \"LLM-based agents\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zkh0YJuCp3Zl",
        "outputId": "d847426e-71b3-47e6-b1ae-351a78d68d1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Context Engineering is a discipline focused on providing AI systems, such as large language models (LLMs), with the necessary information and tools to successfully complete specific tasks. It involves building dynamic systems that supply the right data in the appropriate format at the right time, enabling AI to perform reliably and effectively. \n",
            "\n",
            "The concept has gained prominence around mid-2025, with references to it breaking onto the scene in June and July of that year. It is considered a core skill for developing powerful AI applications, transforming AI from simple chatbots into more capable and context-aware tools.\n",
            "\n",
            "\n",
            "\n",
            "Fine-tuning is a machine learning technique used to adapt a pre-trained model to a specific task or dataset. Instead of training a model from scratch, which can be resource-intensive and time-consuming, fine-tuning involves taking an existing model that has already learned general features from a large dataset and then further training it on a smaller, task-specific dataset. This process helps the model specialize in the new task while leveraging the knowledge it has already acquired.\n",
            "\n",
            "Fine-tuning became prominent with the rise of large pre-trained models in natural language processing (NLP) and computer vision. It gained significant attention around 2018-2019, especially with the advent of models like BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer). These models demonstrated that pre-training on massive datasets followed by fine-tuning on specific tasks could achieve state-of-the-art performance across various applications.\n",
            "\n",
            "In summary:\n",
            "- **What is it?** A transfer learning technique to adapt pre-trained models to specific tasks.\n",
            "- **When did it break onto the scene?** It gained widespread recognition and became a dominant approach around 2018-2019 with models like BERT and GPT.\n",
            "\n",
            "\n",
            "\n",
            "LLM-based agents are systems that utilize large language models (LLMs) to perform complex tasks through reasoning, planning, and execution, often with the help of additional modules like memory and tools. They can handle a wide range of applications, including problem-solving, decision-making, and human-AI interaction. These agents have evolved from simple text-based systems to sophisticated autonomous entities capable of perception, reasoning, and collaboration.\n",
            "\n",
            "The concept of LLM-based agents started gaining significant attention around 2023-2024, with rapid advancements and increased research publications. They have become a practical reality by 2025, transforming how AI systems operate across various domains such as healthcare, enterprise, robotics, and more. The emergence of powerful models like GPT-3 in 2020 marked a pivotal point, but the full realization of LLM agents as autonomous, multi-functional systems has been a more recent development, reaching a broader scene in the AI community by 2023-2024.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for pattern in patterns:\n",
        "  what_is_string = f\"What is {pattern} and when did it break onto the scene??\"\n",
        "  inputs = {\"messages\" : [HumanMessage(content=what_is_string)]}\n",
        "  messages = agent_with_helpfulness_check.invoke(inputs)\n",
        "  print(messages[\"messages\"][-1].content)\n",
        "  print(\"\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
